{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/Training_Deep_NNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSOF_1yqnari"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOl58q-btExy"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLbFutL3tJqY"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVYjGOtbtK1k"
      },
      "outputs": [],
      "source": [
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC3K8J4ZtNoc"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzkH_kKStQMq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oITOkBP5tU-H"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REi4dpDYtaLs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iFLoDR8tctI",
        "outputId": "98c634e0-de86-43d0-a2c3-d91d682e7563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version 2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Version\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGP-SgfzzFMb"
      },
      "outputs": [],
      "source": [
        "fashionmnist = tf.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEgrQS0ckr0P",
        "outputId": "9fb43017-a4a8-44cd-8cdd-57f2ea6ffb13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = fashionmnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOXxOfsek8AR",
        "outputId": "6e7e45dd-355d-4bb7-bf48-c664f4b1e82b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f5e5fd25950>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tf.keras.layers.Dense(10 , activation=\"relu\", kernel_initializer=\"he_normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcyC84hEtQ6d",
        "outputId": "6fa95633-407c-4fe6-cd37-6bf5bbe430bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f5e5f4aca10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "he_avg_init = tf.keras.initializers.VarianceScaling(scale=2.,mode=\"fan_avg\",distribution=\"uniform\")\n",
        "tf.keras.layers.Dense(10, activation=\"sigmoid\",kernel_initializer= he_avg_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmgJBZnrvKtT",
        "outputId": "e9ba210d-45f5-4508-dc39-29c59ea57053"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f5e5f4aced0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "tf.keras.layers.Dense(10, activation=leaky_relu, kernel_initializer=\"he_normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdAayjLb0B0T"
      },
      "outputs": [],
      "source": [
        "#To use the PRelu  parametric leaky relu \n",
        "plrelu = tf.keras.layers.PReLU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHi6HHN2042M",
        "outputId": "e7f83811-0a88-42c8-b00a-03ef0f81f22e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f5e5f4c1d10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#To use the self normalizing linear unit \n",
        "tf.keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By5nD8BB1SXV"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaw6bAlo9Y-b",
        "outputId": "ae861ea8-76d0-4e57-b7b2-7b47fab948f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DEFY7X_9tPt",
        "outputId": "35226d30-f526-4be4-b4a4-3b71cd6095b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbq-kmil-YRT",
        "outputId": "f6d81ff8-15fd-433b-c532-40eac8496aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.layers[1].updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeGMeYYb_Bbv"
      },
      "outputs": [],
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28 ,28]),\n",
        "tf.keras.layers.BatchNormalization(),#Batch normalization is used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"), #Weight initialization techniques are also used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.BatchNormalization(), \n",
        "tf.keras.layers.Activation(\"elu\"), #Different variants of activation functions are also used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjfnIPKwB0em",
        "outputId": "8154d506-a106-410f-c50f-5a26d308fd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "#Saving the model \n",
        "\n",
        "#Imports\n",
        "!pip install pyyaml h5py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZHNJuidG_6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b432931-3b17-4e3b-916d-a7c136c471fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Load the model and split\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghbcm1vbHa5Q"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbGuNoAiHhwW"
      },
      "outputs": [],
      "source": [
        "train_images = train_images[:1000].reshape(-1, 28,28) #We take 1000 images from the training set and put them int a vector of 28 * 28 rows one colum\n",
        "train_images = train_images/255.0 #We turn our input features into floating points between 0 and 1 this is called normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0jhyDIRIM1X"
      },
      "outputs": [],
      "source": [
        "test_images = test_images[:1000].reshape(-1,28,28) /255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiallImTIloE"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "  tf.keras.layers.BatchNormalization(), #Included batch norm before and after every hidden layer to prevent vanishing and exploding gradients \n",
        "  #Batch norm invloves zero centering and normalizing the inputs\n",
        "  tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kia55-RD6fLq",
        "outputId": "70c96920-187b-4701-9775-dd0cf3bbc999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 784)              3136      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDrqzPNB7Vee",
        "outputId": "9208a783-ce8b-4708-9bb9-507077ed7b83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization_6/gamma:0', True),\n",
              " ('batch_normalization_6/beta:0', True),\n",
              " ('batch_normalization_6/moving_mean:0', False),\n",
              " ('batch_normalization_6/moving_variance:0', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evz3viT9796-"
      },
      "outputs": [],
      "source": [
        "#Using batch normalization just after the hidden layers\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "  tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Activation(\"elu\"),\n",
        "  tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.Activation(\"elu\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "  ]) #This is how we use batch normalization after every hidden layer in our neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHTmEv5_--Pn",
        "outputId": "6222033d-e8ad-48ce-8e88-f789d8f493e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.optimizer_v2.gradient_descent.SGD at 0x7f5e5b4c5190>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#Implementing gradient clipping in tensorflow\n",
        "tf.keras.optimizers.SGD(clipvalue=1.0)#This will clip the value to be in between -1 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRXhy9vyGnMK",
        "outputId": "56350871-b3ac-49f8-f28d-5931e663aba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"myModel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysh5Q3s0NCFq",
        "outputId": "11e4df26-743e-4d33-962e-006662b917e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#Transfer learning with keras.\n",
        "#We load the model \n",
        "model_A = tf.keras.models.load_model(\"myModel.h5\")\n",
        "model_B_on_A = tf.keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\n",
        "#These two models share the same layers and parameters so when you train the new model, the original model will be affected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLZCstpMPCLF"
      },
      "outputs": [],
      "source": [
        "#We clone the model and copy its parameters\n",
        "model_A_clone = tf.keras.models.clone_model(model_A) #We clone the layers of the original model\n",
        "model_A_clone = model_A_clone.set_weights(model_A.get_weights()) #We copy the parameters of the first model and apply them to the clone of the  original model\n",
        "#By doing so the parameter of the original model won't be affected by gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_7ogMCiQu9X"
      },
      "outputs": [],
      "source": [
        "#We have to freeze the cloned model's higher level layers to prevent the model from making huge errors \n",
        "#We freeze the layers by setting the trainable parameters to false of a specific layer\n",
        "\n",
        "for layer in model_A.layers[:-1]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmtraqQlThVv"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnqRG1s-aT9S",
        "outputId": "fd38ceea-f7fd-4c63-f7cb-14875bc3b454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: MyModel.H5/assets\n"
          ]
        }
      ],
      "source": [
        "model = model.save(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe_43NvkcPff",
        "outputId": "b7275450-508d-4c5c-e051-bde271b17e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#Load the model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDJLTRXwdCWI"
      },
      "outputs": [],
      "source": [
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1]) #We remove the output layer and add our own "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGl2FPOna14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "0671ccbe-e703-4739-cc60-e97e3ff5970b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-d0d14b8cf141>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    tf.keras.layers.Flatten(input_shape=train_images[0].shape]),\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#Transfer learning with keras\n",
        "\n",
        "#Lets create a sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=train_images[0].shape]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vQ0iHZAMpdDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "aEpJxH0zfqUt",
        "outputId": "8fe54753-5c17-4972-cff0-3e0eac645266"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4790190e18b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lets save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MyModel.H5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
          ]
        }
      ],
      "source": [
        "#Lets save the model \n",
        "model = model.save(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAZZZv5rf4vH",
        "outputId": "62fce017-3495-421b-9797-443bbce32862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#Lets load the model\n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-dDjh4-h5ma"
      },
      "outputs": [],
      "source": [
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1]) #We remove the last layer of our model to suit the task  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGOCsxpdiycC"
      },
      "outputs": [],
      "source": [
        "#We add another layers based on the task we are trying to solve \n",
        "model_A_on_B.add(tf.keras.layers.Dense(1, activation=\"sigmoid\")) #We add a dense layer of 1 neuron and a sigmoid activation function to better suit our task \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8SS9mbfjIuP"
      },
      "outputs": [],
      "source": [
        "#When we train the new model backpropagation will affect model_A  to avoid this we should clone the model \n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-EwhRI6lfEa"
      },
      "outputs": [],
      "source": [
        "for layer in model_A_clone.layers[:-1]: #We freeze the layers of our model \n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F60zb79Ynexc"
      },
      "outputs": [],
      "source": [
        "#We compile the model after we freeze and unfreeze the layers\n",
        "model_A_clone.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoDj6gpbohR7",
        "outputId": "0ff105b0-aef8-4300-d5a8-bd09b855f548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#We load the saved model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw6JgG1NpNYa"
      },
      "outputs": [],
      "source": [
        "#We remove the last layer(Output layer) of our model since we have a different task \n",
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfVd7GnPTids"
      },
      "outputs": [],
      "source": [
        "#We add our own output layer\n",
        "model_A_on_B.add(tf.keras.layers.Dense(1,activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K42WxrP_qcLl"
      },
      "outputs": [],
      "source": [
        "#Cloning the model\n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "#We set the weights \n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Uo-XQYtLdd"
      },
      "outputs": [],
      "source": [
        "#We can also freeze layers in our model\n",
        "for layer in model_A_clone.layers[:-1]:\n",
        "  layer.trainable =False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhUOj3ggt6Sm"
      },
      "outputs": [],
      "source": [
        "#After we freeze we compile our model \n",
        "model_A_clone.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"Accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG9Av5BJuM0f"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkVYXpMAvd0_"
      },
      "outputs": [],
      "source": [
        "fashionmnist = tf.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btc3gWq8vtCE",
        "outputId": "8e410590-46b9-4570-a6f9-260a53ac2471"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras.api._v2.keras.datasets.mnist' from '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/mnist/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVGW5MfrwLCm"
      },
      "outputs": [],
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMPKCfbM1Gq2",
        "outputId": "55ff62be-8543-4ae5-b325-3efc5a27b459"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kD4rat21IPF",
        "outputId": "27089a48-43a2-428e-ebf6-c5920b9b6ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE7isDodwovI"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train/255.0,x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBMK3huCz5Qq",
        "outputId": "73d11d5a-e0d8-4040-b77a-ec1b94a93b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvSEg_q4z83v",
        "outputId": "68b8d36a-f426-490b-9e37-d11112d65044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "y_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KBevSQp0z07",
        "outputId": "a213d419-3044-4467-ebd5-c216d853f1d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMDJ2OhLwyUw"
      },
      "outputs": [],
      "source": [
        "#Fashion Mnist\n",
        "(train_images_full, train_labels) ,(test_images_full, test_labels) = fashionmnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iangq-XQxCao"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_images = train_images/255.0 \n",
        "test_images = test_images /255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coxg65IBzFoC"
      },
      "outputs": [],
      "source": [
        "cb =tf.keras.callbacks.EarlyStopping( patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qypjj4DYxaOp"
      },
      "outputs": [],
      "source": [
        "model_A_clone.fit(x_train, y_train, epochs=4)\n",
        "#Fix error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIzo5V1rdghK"
      },
      "source": [
        "In transfer learning if the input features of your task don't have the same size like the one of the original model then you have to add a preprocessing step to resize the size of your images to be closer to the one of the original task. The output layer of the original model should always be replaced since they might not have the intented number of output as the original task. The upper hidden layers are less likely to be useful as the lower hidden layers since the task might differ significantly from the ones that were most useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_ZDTSNczb-Z"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(1,activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2n0nRe5kiBc"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSlZ9iZ3k3Qj"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train,y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6w-EMihlreS"
      },
      "outputs": [],
      "source": [
        "#cb = tf.keras.callbacks.ModelCheckpoint(save) DO SAVING THE MODEL ONCE AGAIN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RcOIBkelb0Y"
      },
      "outputs": [],
      "source": [
        "model.save(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2aWLXdemnzA"
      },
      "outputs": [],
      "source": [
        "#We load the model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGg8r8Lem58z"
      },
      "outputs": [],
      "source": [
        "#We create a new model based on the layers of the loaded model \n",
        "model_A_reloaded = tf.keras.models.Sequential(model_A.layers[:-1]) #We also remove the last layer of this model since the  task is different from the original one which means the output layer should have different number of neurons\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLLZCe5moCsx"
      },
      "outputs": [],
      "source": [
        "#We add our own output layer\n",
        "model_A_reloaded.add(tf.keras.layers.Dense(1, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CuUpr90oTFo"
      },
      "outputs": [],
      "source": [
        "#Cloning the model \n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "#This clone comes without parameters so we set them \n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j7cHBybpCWG"
      },
      "outputs": [],
      "source": [
        "#We freeze the layers \n",
        "for layer in model_A_clone.layers[:-1]: #To freeze the layers we set every layers trainable attributes to false\n",
        "  layer.trainable = False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnmLBFotqOSA"
      },
      "outputs": [],
      "source": [
        "model_A_clone.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUwRe1E_2bZW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msboPW7Vqsgv"
      },
      "outputs": [],
      "source": [
        "#We should compile the model after we freeze of unfreeze a particular layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p77PNUejk1km"
      },
      "outputs": [],
      "source": [
        "model_A_clone.layers[:-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti594yx_lAxT"
      },
      "outputs": [],
      "source": [
        "model_A_clone.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J9wE6_hluP1"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRDWJ5GPlkqJ"
      },
      "outputs": [],
      "source": [
        "model_A_clone.layers[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxWgRjE1l2y7"
      },
      "outputs": [],
      "source": [
        "model_A_clone.layers[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsvQh4Hml6Pb"
      },
      "outputs": [],
      "source": [
        "model_A_New = tf.keras.models.Sequential(model_A_clone.layers[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5kgO_ypmO6k"
      },
      "outputs": [],
      "source": [
        "model_A_New1 = tf.keras.models.Sequential(model_A_New.layers[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHXy8_P8mbIJ"
      },
      "outputs": [],
      "source": [
        "model_A_New1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjWJ9K4Imd-Z"
      },
      "outputs": [],
      "source": [
        "model_A_New1.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCiKvhl_mvB5"
      },
      "outputs": [],
      "source": [
        "model_A_New1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPKbxQyimyYW"
      },
      "outputs": [],
      "source": [
        "model_A_New.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6FQjX5GnEEu"
      },
      "outputs": [],
      "source": [
        "model_A_New.fit(x_train,y_train,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR_emLz1sHGz"
      },
      "outputs": [],
      "source": [
        "model_A_clone.fit(x_train, y_train, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfFpnz73q4yD"
      },
      "outputs": [],
      "source": [
        "mnistOne= tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5AQ3bJJrOYh"
      },
      "outputs": [],
      "source": [
        "(x_train_full,x_test),(y_train_full, y_test) = mnistOne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0YWuTetrdoj"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-learn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHCQFdRAydvV"
      },
      "outputs": [],
      "source": [
        "mnistOne = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhfgWCvWynUA"
      },
      "outputs": [],
      "source": [
        "(x_train_full, x_test),(y_train_full, y_test) = mnistOne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJzKm_lvzu4q"
      },
      "outputs": [],
      "source": [
        "x_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmQXZ5y6zwYQ"
      },
      "outputs": [],
      "source": [
        "y_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o89pFG1AzU2u"
      },
      "outputs": [],
      "source": [
        "x_train,x_valid = x_train_full[:5000], x_train_full[:5000]\n",
        "y_train,y_valid = y_train_full[:5000], y_train_full[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fj4dfFyx4t1e"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rk__oqpzVLb"
      },
      "outputs": [],
      "source": [
        "model_A_clone.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDm7Th8S1CGV"
      },
      "outputs": [],
      "source": [
        "model_A_clone.fit(x_train,y_train,epochs=5, validation_data=[x_valid, y_valid])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjPrrYE014th"
      },
      "outputs": [],
      "source": [
        "model_A_clone.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kVtIC9G2BI5"
      },
      "outputs": [],
      "source": [
        "#Freezing layers during transfer learning \n",
        "for layer in model_A_clone.layers[:-1]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DIEAbYosI_i"
      },
      "outputs": [],
      "source": [
        "#Unfreezing layers during transfer learning\n",
        "for layer in model_A_clone.layers[:-1]:\n",
        "  layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djgqwQjDsUlr"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBa2kn9y_o27"
      },
      "source": [
        "Ways of speeding up training of a deep neural network \n",
        "- Using a good weight initialization strategy.\n",
        "- Using a different variants of activation functions.\n",
        "- Using batch normalisation.\n",
        "- Using parts of a pretrained neural network or so called transfer learning.\n",
        "\n",
        "Another way of boosting the training of a deep neural network is using other optimizers than the regular or vanilla gradient descent algorithm.\n",
        "Other optimization strategies include: \n",
        "Momentum optimization, Nesterov Accelerated gradient, RMS prop ,AdaGrad, Adam and Nadam optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL8IzCr0tDAF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "optimizers = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3uPPHGOL--e"
      },
      "source": [
        "Another faster optimization algorithm that is almost faster than vanilla momentum optmization is Nesterov Momentum optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5TrEI-wFFKf"
      },
      "outputs": [],
      "source": [
        "#Implementing the Nesterov Accelerated Gradient or Nesterov momentum optimization function \n",
        "optimizers = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Jg20cjNzcI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqglH2ZEYb0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b373cd60-d808-40e3-b5f4-b66806563a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Version: \", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUfueo-eYgnB"
      },
      "outputs": [],
      "source": [
        "#We load  and split the data\n",
        "(train_images,train_labels), (test_images, test_labels) =tf.keras.datasets.mnist.load_data() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4GR98UUmqA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2d91b7-9d9c-4511-a0f4-bd3ad32af609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJNs7qHsm5TG"
      },
      "outputs": [],
      "source": [
        "train_images = train_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHi4DBMxm-ya"
      },
      "outputs": [],
      "source": [
        "test_images = test_images/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eGn7KsznDWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96038ce1-5d6b-470b-cb76-5a72c357c218"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "train_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4ZefnnxZ2ph"
      },
      "outputs": [],
      "source": [
        "#We create the sequential model \n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\", name=\"Hidden1\"),\n",
        "tf.keras.layers. Activation('elu'),\n",
        "tf.keras.layers.Dense(100,kernel_initializer=\"he_normal\", name=\"Hidden2\"),\n",
        "tf.keras.layers.Activation('elu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10,activation=\"softmax\", name=\"Output\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnj8pQWongwT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJLMnb16ay21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1751f5cd-d3d0-4544-89df-f3d0389e2bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 784)              3136      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " Hidden1 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 300)               0         \n",
            "                                                                 \n",
            " Hidden2 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " Output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270,146\n",
            "Trainable params: 268,378\n",
            "Non-trainable params: 1,768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVld9rg_a042"
      },
      "outputs": [],
      "source": [
        "#Compile the model \n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"Adam\",metrics=[tf.keras.metrics.Accuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUedplclhZYZ"
      },
      "outputs": [],
      "source": [
        "def createModel():\n",
        "  model = tf.keras.models.Sequential([\n",
        "   tf.keras.layers.Flatten(input_shape=(28,28), name=\"InputLayer\"),\n",
        "   tf.keras.layers.BatchNormalization(),\n",
        "   tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\",name=\"HiddenLayer1\"),\n",
        "   tf.keras.layers.Activation('elu'),\n",
        "   tf.keras.layers.Dense(100,kernel_initializer=\"he_normal\", name=\"HiddenLayer2\"),\n",
        "   tf.keras.layers.Activation('elu'),\n",
        "   tf.keras.layers.BatchNormalization(),\n",
        "   tf.keras.layers.Dense(10, activation=\"softmax\", name=\"OutputLayer\")   \n",
        "  ])\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"Adam\", metrics=[tf.keras.metrics.Accuracy()])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwEuVATgoNVH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgPJoShsjN9Y"
      },
      "outputs": [],
      "source": [
        "model = createModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUY1wc7yjdb5"
      },
      "outputs": [],
      "source": [
        "model.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cri64Zx2jpMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1cdec7-61f6-40a3-b24b-6b524a139274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " InputLayer (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 784)              3136      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " HiddenLayer1 (Dense)        (None, 300)               235500    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 300)               0         \n",
            "                                                                 \n",
            " HiddenLayer2 (Dense)        (None, 100)               30100     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 100)              400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " OutputLayer (Dense)         (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270,146\n",
            "Trainable params: 268,378\n",
            "Non-trainable params: 1,768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwneogGYjyk3"
      },
      "outputs": [],
      "source": [
        "#Lets create a callback checkpoint that saves the model's weights during training\n",
        "#Create the check point path\n",
        "cp_path = \"train_one/cp.ckpt\" #Check point path\n",
        "cp_dir = os.path.dirname(cp_path) #Check point directory \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEy2S_kKaHP-"
      },
      "outputs": [],
      "source": [
        "#Lets create a callback that save the model's weights durin training\n",
        "cb = tf.keras.callbacks.ModelCheckpoint(cp_path,verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX3qhhD9mEjD"
      },
      "outputs": [],
      "source": [
        "#Lets train the model with the callbacks assigned \n",
        "history = model.fit(train_images, train_labels,epochs =10 , validation_data=(test_images, test_labels), callbacks=[cb])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "lviIIP928xo8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for the tensorflow version\n",
        "print(\"Version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jbFSx0188Sd",
        "outputId": "23883c7e-3519-4e93-f2e4-cfd7dedec3ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "indKg7SN8y27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1946c1d3-7e4b-4730-ecb7-0d8b05c095fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels), (test_images,test_labels) = mnist"
      ],
      "metadata": {
        "id": "W2KE5cbI9nby"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We normalize the data to avoid decreasing training accuracy and reduce bias in data which might affect learning\n",
        "train_images= train_images/255.0 "
      ],
      "metadata": {
        "id": "WiZSnY3d-Efx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images= test_images/255.0"
      ],
      "metadata": {
        "id": "GE80R4gI-UJ4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create our model\n",
        "def createModel():\n",
        "  model = tf.keras.models.Sequential([\n",
        "     tf.keras.layers.Flatten(input_shape=train_images[0].shape),\n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "     tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "     tf.keras.layers.Activation('elu'),\n",
        "     tf.keras.layers.Dense(100,kernel_initializer=\"he_normal\"),\n",
        "     tf.keras.layers.Activation('elu'), \n",
        "     tf.keras.layers.BatchNormalization(),\n",
        "     tf.keras.layers.Dense(10,activation='softmax')\n",
        "  ])\n",
        "  #Specify the hyperparameters\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=\"Adam\", metrics=['Accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "nyteadK_-XMu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = createModel()"
      ],
      "metadata": {
        "id": "UDIPIGHaBEvK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We create a check point and pass it to a callback\n",
        "cp = \"train_1/cp.ckpt\"\n",
        "cb = tf.keras.callbacks.ModelCheckpoint(cp, verbose=1, save_best_only=True)\n",
        "history = model.fit(train_images, train_labels,epochs=20,validation_data=[test_images, test_labels],callbacks=[cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzkoTh2yBG96",
        "outputId": "e5fa4738-0cb7-48c2-ce57-fc09ec93bf25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0311 - Accuracy: 0.9890\n",
            "Epoch 8: val_loss improved from 0.08996 to 0.08799, saving model to train_1/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: train_1/cp.ckpt/assets\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0311 - Accuracy: 0.9890 - val_loss: 0.0880 - val_Accuracy: 0.9780\n",
            "Epoch 9/20\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0275 - Accuracy: 0.9914\n",
            "Epoch 9: val_loss did not improve from 0.08799\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0275 - Accuracy: 0.9914 - val_loss: 0.0953 - val_Accuracy: 0.9775\n",
            "Epoch 10/20\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0240 - Accuracy: 0.9919\n",
            "Epoch 10: val_loss did not improve from 0.08799\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0240 - Accuracy: 0.9919 - val_loss: 0.0957 - val_Accuracy: 0.9782\n",
            "Epoch 11/20\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0233 - Accuracy: 0.9923\n",
            "Epoch 11: val_loss improved from 0.08799 to 0.08219, saving model to train_1/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: train_1/cp.ckpt/assets\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0233 - Accuracy: 0.9923 - val_loss: 0.0822 - val_Accuracy: 0.9807\n",
            "Epoch 12/20\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0210 - Accuracy: 0.9931\n",
            "Epoch 12: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0209 - Accuracy: 0.9931 - val_loss: 0.1042 - val_Accuracy: 0.9803\n",
            "Epoch 13/20\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.0191 - Accuracy: 0.9937\n",
            "Epoch 13: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0192 - Accuracy: 0.9937 - val_loss: 0.1058 - val_Accuracy: 0.9809\n",
            "Epoch 14/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0186 - Accuracy: 0.9936\n",
            "Epoch 14: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0186 - Accuracy: 0.9936 - val_loss: 0.1039 - val_Accuracy: 0.9785\n",
            "Epoch 15/20\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0169 - Accuracy: 0.9947\n",
            "Epoch 15: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0169 - Accuracy: 0.9947 - val_loss: 0.0995 - val_Accuracy: 0.9803\n",
            "Epoch 16/20\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.0162 - Accuracy: 0.9945\n",
            "Epoch 16: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0162 - Accuracy: 0.9944 - val_loss: 0.1013 - val_Accuracy: 0.9802\n",
            "Epoch 17/20\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0150 - Accuracy: 0.9950\n",
            "Epoch 17: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0150 - Accuracy: 0.9950 - val_loss: 0.1040 - val_Accuracy: 0.9806\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0149 - Accuracy: 0.9947\n",
            "Epoch 18: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0149 - Accuracy: 0.9947 - val_loss: 0.1037 - val_Accuracy: 0.9786\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0149 - Accuracy: 0.9952\n",
            "Epoch 19: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0149 - Accuracy: 0.9952 - val_loss: 0.1062 - val_Accuracy: 0.9795\n",
            "Epoch 20/20\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0123 - Accuracy: 0.9960\n",
            "Epoch 20: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0124 - Accuracy: 0.9960 - val_loss: 0.1103 - val_Accuracy: 0.9806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We clone the model"
      ],
      "metadata": {
        "id": "5ZocRAmuCr0r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing momentum optmizer\n",
        "#We use SGD optimizer\n",
        "momentum = tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9)\n",
        "#A major drawback of momentum optimizer is that it adds another hyperparameter to tune but its faster than vanilla gradient descent"
      ],
      "metadata": {
        "id": "Br7Gwam-B7NV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To speed up the training of deep neural networks we can use different weight initializatin techniques, different activation functions, re-using parts of pre-trained neural networks and using faster optimizers\n",
        "nesterov= tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "mt3kfloMqcun"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RMS prop that fixes the ada grad problem of stopping the training early while not converging to the global minimum by  accumulating the gradients of the recent iterations as opposed to all the gradients from the beginning of training"
      ],
      "metadata": {
        "id": "J190FY0iuVa7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9) #This optimization algorithm almost always performs better than adaGrad except on very simple problems"
      ],
      "metadata": {
        "id": "uy_E9Gnx2BOG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam or adaptive momentum optimization combines the ideas\n",
        " RMSprop and momentum  optimization. It keeps track of exponentially decaying average of past gradients just like momentum optmization. And just like RMS prop it keeps track of exponentially decaying average of squared gradients."
      ],
      "metadata": {
        "id": "FIC4rVvM3yrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = tf.keras.optimizers.Adam(learning_rate=0.9, beta_1=0.9, beta_2=0.999)"
      ],
      "metadata": {
        "id": "UqSALgvm3NK0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001,decay=1e-4)"
      ],
      "metadata": {
        "id": "TdMjxbNzBjs5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning scheduling are strategies that are used to reduce the learning rate during training. "
      ],
      "metadata": {
        "id": "tjFtG8NmEAWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay_fn(epoch):\n",
        "  return  0.001 * 0.1**(epoch/20) "
      ],
      "metadata": {
        "id": "8628zE70DeVY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay(lr0,s):\n",
        "  def exponential_decay_fn(epoch):\n",
        "    return lr0 * 0.1 **(epoch /s)\n",
        "  return exponential_decay_fn"
      ],
      "metadata": {
        "id": "KdiM5YqTHAbC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_decay = exponential_decay(0.001, 20)"
      ],
      "metadata": {
        "id": "wjpsfy2yJIPO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, decay=1e-4) #1e-4 is 1 * 10 ^ -4 \n",
        "#The decay is the inverse of s(Number of steps it takes to divide the inverse more by one unit)"
      ],
      "metadata": {
        "id": "hPdcmpcFJxgq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Power scheduling learning rate \n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1,decay=1e-4)"
      ],
      "metadata": {
        "id": "vPv5K8SFI0Kt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exponential scheduling \n",
        "def exponential_decay_fn(epoch):\n",
        "  return 0.001 * 0.1 ** (epoch/20)"
      ],
      "metadata": {
        "id": "7QbmRv4Y6Sk7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If we do not want to hardcode the  learning rate and the  steps s we can create a function that returns a function \n",
        "def exponential_decay(lr,s):\n",
        "  def exponential_decay_fn(epoch):\n",
        "    return lr * 0.1 **(epoch/s)"
      ],
      "metadata": {
        "id": "6QeRTQ6B6jFs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function that returns a function \n",
        "def exponential_decay(lr,s):\n",
        "  def exponential_decay_fn(epoch):\n",
        "    return lr * 0.1 **(epoch/s)\n",
        "  return exponential_decay_fn"
      ],
      "metadata": {
        "id": "39YCvVob63_r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_decay_fn = exponential_decay(lr=0.01,s=20)"
      ],
      "metadata": {
        "id": "hKAFAIBT8jDp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating the exponential function we create a learning rate call back, call the learning rate scheduler and pass the exponential function as an argument and then pass the call back to the fit method\n"
      ],
      "metadata": {
        "id": "o1TXGiCx-oAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
      ],
      "metadata": {
        "id": "EUPfFxPC95ng"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pass the callback to the fit method \n",
        "history = model.fit(train_images, train_labels, epochs=5, validation_data=[test_images, test_labels], callbacks=[cb,callback_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0acep35N-ylY",
        "outputId": "1d6198f9-fb55-4430-858a-9d5901a7bf3f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0665 - Accuracy: 0.9785\n",
            "Epoch 1: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0664 - Accuracy: 0.9785 - val_loss: 0.1016 - val_Accuracy: 0.9743 - lr: 0.0100\n",
            "Epoch 2/5\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0480 - Accuracy: 0.9844\n",
            "Epoch 2: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0479 - Accuracy: 0.9844 - val_loss: 0.0924 - val_Accuracy: 0.9773 - lr: 0.0089\n",
            "Epoch 3/5\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0368 - Accuracy: 0.9880\n",
            "Epoch 3: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0368 - Accuracy: 0.9880 - val_loss: 0.1092 - val_Accuracy: 0.9759 - lr: 0.0079\n",
            "Epoch 4/5\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0337 - Accuracy: 0.9891\n",
            "Epoch 4: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0336 - Accuracy: 0.9891 - val_loss: 0.0986 - val_Accuracy: 0.9808 - lr: 0.0071\n",
            "Epoch 5/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0269 - Accuracy: 0.9911\n",
            "Epoch 5: val_loss did not improve from 0.08219\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0269 - Accuracy: 0.9911 - val_loss: 0.1169 - val_Accuracy: 0.9780 - lr: 0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R98_rl2lAMb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0XEHfTJF_TyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vFmSCpfM94mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5xmSTVcL92dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h2J4u8ag8jQJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6SODgi7P8kGv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dJlMCETc8kNs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rf0bxArZ8kjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Training Deep NNs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOX01gjg120HlbYSd9vdTiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}