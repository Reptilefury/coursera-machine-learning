{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Deep NNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa6f6In9OnkUbtHrtWJt+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/Training_Deep_NNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uSOF_1yqnari"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "GOl58q-btExy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "pLbFutL3tJqY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "SVYjGOtbtK1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "yC3K8J4ZtNoc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "MzkH_kKStQMq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "oITOkBP5tU-H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import losses"
      ],
      "metadata": {
        "id": "REi4dpDYtaLs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Version\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iFLoDR8tctI",
        "outputId": "c4ce8ef3-4121-4425-f7b4-ee817789d2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashionmnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "HGP-SgfzzFMb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels),(test_images, test_labels) = fashionmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEgrQS0ckr0P",
        "outputId": "4a27e6ed-ddf2-437c-fd58-8e0f131f4e32"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Dense(10 , activation=\"relu\", kernel_initializer=\"he_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOXxOfsek8AR",
        "outputId": "b83c97e4-b9e7-440d-b6f2-5df7c9dc0d39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f40bd5f6110>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "he_avg_init = tf.keras.initializers.VarianceScaling(scale=2.,mode=\"fan_avg\",distribution=\"uniform\")\n",
        "tf.keras.layers.Dense(10, activation=\"sigmoid\",kernel_initializer= he_avg_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcyC84hEtQ6d",
        "outputId": "e3b1828d-db29-47ee-feba-f6bf9b038128"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f40bc950a50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "tf.keras.layers.Dense(10, activation=leaky_relu, kernel_initializer=\"he_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmgJBZnrvKtT",
        "outputId": "ce851571-ccf9-4ab9-866f-95d89e526ec4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f40bd5e6b90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To use the PRelu  parametric leaky relu \n",
        "plrelu = tf.keras.layers.PReLU()"
      ],
      "metadata": {
        "id": "RdAayjLb0B0T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To use the self normalizing linear unit \n",
        "tf.keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHi6HHN2042M",
        "outputId": "7b1836c7-5fd7-4b11-af0f-b7b4bed4f978"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f40bc8e4c10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "By5nD8BB1SXV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaw6bAlo9Y-b",
        "outputId": "90c6f2f4-ae50-48b6-91b1-1fd7eddbca39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DEFY7X_9tPt",
        "outputId": "f8a638ae-d575-42d2-a85f-e2cafec3dfb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[1].updates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbq-kmil-YRT",
        "outputId": "eda7b0cf-6d96-418c-baaf-e4655f2b0eca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28 ,28]),\n",
        "tf.keras.layers.BatchNormalization(),#Batch normalization is used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"), #Weight initialization techniques are also used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.BatchNormalization(), \n",
        "tf.keras.layers.Activation(\"elu\"), #Different variants of activation functions are also used to prevent vanishing and exploding gradients\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "eeGMeYYb_Bbv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the model \n",
        "\n",
        "#Imports\n",
        "!pip install pyyaml h5py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjfnIPKwB0em",
        "outputId": "b00df8bd-4b21-46eb-a83f-f6dc31f0ddca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model and split\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZHNJuidG_6j",
        "outputId": "0efae7f1-1d65-46ff-9657-da79fe4a2b46"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]"
      ],
      "metadata": {
        "id": "Ghbcm1vbHa5Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images[:1000].reshape(-1, 28,28) #We take 1000 images from the training set and put them int a vector of 28 * 28 rows one colum\n",
        "train_images = train_images/255.0 #We turn our input features into floating points between 0 and 1 this is called normalization"
      ],
      "metadata": {
        "id": "ZbGuNoAiHhwW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images[:1000].reshape(-1,28,28) /255.0"
      ],
      "metadata": {
        "id": "M0jhyDIRIM1X"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "  tf.keras.layers.BatchNormalization(), #Included batch norm before and after every hidden layer to prevent vanishing and exploding gradients \n",
        "  #Batch norm invloves zero centering and normalizing the inputs\n",
        "  tf.keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(100, activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "  ])"
      ],
      "metadata": {
        "id": "yiallImTIloE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kia55-RD6fLq",
        "outputId": "3f18a5d0-90d6-4234-e68d-a4fd207a55ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 784)              3136      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(var.name, var.trainable) for var in model.layers[1].variables]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDrqzPNB7Vee",
        "outputId": "d3e28989-4051-4290-90d2-a8468e51941b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization_6/gamma:0', True),\n",
              " ('batch_normalization_6/beta:0', True),\n",
              " ('batch_normalization_6/moving_mean:0', False),\n",
              " ('batch_normalization_6/moving_variance:0', False)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using batch normalization just after the hidden layers\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "  tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Activation(\"elu\"),\n",
        "  tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "  tf.keras.layers.Activation(\"elu\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "  ]) #This is how we use batch normalization after every hidden layer in our neural network"
      ],
      "metadata": {
        "id": "evz3viT9796-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing gradient clipping in tensorflow\n",
        "tf.keras.optimizers.SGD(clipvalue=1.0)#This will clip the value to be in between -1 and 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHTmEv5_--Pn",
        "outputId": "5f2d8f52-5686-4b2b-8216-26d5ba6f84e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.optimizer_v2.gradient_descent.SGD at 0x7f40b88e43d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"myModel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRXhy9vyGnMK",
        "outputId": "b6286dbb-f9a6-4021-c27c-c564834b241b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transfer learning with keras.\n",
        "#We load the model \n",
        "model_A = tf.keras.models.load_model(\"myModel.h5\")\n",
        "model_B_on_A = tf.keras.models.Sequential(model_A.layers[:-1])\n",
        "model_B_on_A.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\n",
        "#These two models share the same layers and parameters so when you train the new model, the original model will be affected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysh5Q3s0NCFq",
        "outputId": "df8e0172-ea8d-4e8b-ec81-b6fbda07b508"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We clone the model and copy its parameters\n",
        "model_A_clone = tf.keras.models.clone_model(model_A) #We clone the layers of the original model\n",
        "model_A_clone = model_A_clone.set_weights(model_A.get_weights()) #We copy the parameters of the first model and apply them to the clone of the  original model\n",
        "#By doing so the parameter of the original model won't be affected by gradient descent."
      ],
      "metadata": {
        "id": "vLZCstpMPCLF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We have to freeze the cloned model's higher level layers to prevent the model from making huge errors \n",
        "#We freeze the layers by setting the trainable parameters to false of a specific layer\n",
        "\n",
        "for layer in model_A.layers[:-1]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "b_7ogMCiQu9X"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "WmtraqQlThVv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.save(\"MyModel.H5\")"
      ],
      "metadata": {
        "id": "AnqRG1s-aT9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f424e96-5b42-4489-830c-05f808f939c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: MyModel.H5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe_43NvkcPff",
        "outputId": "38ca49e6-6c10-44e6-cac3-4fbe9961c7b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1]) #We remove the output layer and add our own "
      ],
      "metadata": {
        "id": "iDJLTRXwdCWI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transfer learning with keras\n",
        "\n",
        "#Lets create a sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "IGl2FPOna14d"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets save the model \n",
        "model = model.save(\"MyModel.H5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEpJxH0zfqUt",
        "outputId": "f4159edb-685c-4ed2-8298-e1548e5a22f5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: MyModel.H5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets load the model\n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAZZZv5rf4vH",
        "outputId": "927ccd5a-dff5-42d0-f968-d102a964e7ec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1]) #We remove the last layer of our model to suit the task  "
      ],
      "metadata": {
        "id": "C-dDjh4-h5ma"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We add another layers based on the task we are trying to solve \n",
        "model_A_on_B.add(tf.keras.layers.Dense(1, activation=\"sigmoid\")) #We add a dense layer of 1 neuron and a sigmoid activation function to better suit our task \n"
      ],
      "metadata": {
        "id": "BGOCsxpdiycC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When we train the new model backpropagation will affect model_A  to avoid this we should clone the model \n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "metadata": {
        "id": "M8SS9mbfjIuP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_A_clone.layers[:-1]: #We freeze the layers of our model \n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "X-EwhRI6lfEa"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We compile the model after we freeze and unfreeze the layers\n",
        "model_A_clone.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "F60zb79Ynexc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We load the saved model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoDj6gpbohR7",
        "outputId": "2c86a8d1-e60f-41ff-9308-31b5ee9de57a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We remove the last layer(Output layer) of our model since we have a different task \n",
        "model_A_on_B = tf.keras.models.Sequential(model_A.layers[:-1])"
      ],
      "metadata": {
        "id": "Rw6JgG1NpNYa"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We add our own output layer\n",
        "model_A_on_B.add(tf.keras.layers.Dense(1,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "RfVd7GnPTids"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cloning the model\n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "#We set the weights \n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "metadata": {
        "id": "K42WxrP_qcLl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can also freeze layers in our model\n",
        "for layer in model_A_clone.layers[:-1]:\n",
        "  layer.trainable =False"
      ],
      "metadata": {
        "id": "90Uo-XQYtLdd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After we freeze we compile our model \n",
        "model_A_clone.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"Accuracy\"])"
      ],
      "metadata": {
        "id": "fhUOj3ggt6Sm"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "LG9Av5BJuM0f"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashionmnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "xkVYXpMAvd0_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btc3gWq8vtCE",
        "outputId": "304aa165-d226-49b4-b079-02b213bf2e47"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras.api._v2.keras.datasets.mnist' from '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/datasets/mnist/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "VVGW5MfrwLCm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMPKCfbM1Gq2",
        "outputId": "f2bf2b5b-e44e-41da-987f-3545544c306b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kD4rat21IPF",
        "outputId": "d5bcd702-79b0-4f96-f793-0be30a535cf4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train/255.0,x_test/255.0"
      ],
      "metadata": {
        "id": "OE7isDodwovI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBMK3huCz5Qq",
        "outputId": "38bf588d-0d5a-45fc-c690-68634954084f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvSEg_q4z83v",
        "outputId": "96a4d467-950b-4f16-c0ac-20e9b93b9a13"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KBevSQp0z07",
        "outputId": "e032009c-21ed-4877-fe66-65c5453506ac"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fashion Mnist\n",
        "(train_images_full, train_labels) ,(test_images_full, test_labels) = fashionmnist.load_data()\n"
      ],
      "metadata": {
        "id": "nMDJ2OhLwyUw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images = train_images/255.0 \n",
        "test_images = test_images /255.0"
      ],
      "metadata": {
        "id": "Iangq-XQxCao"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb =tf.keras.callbacks.EarlyStopping( patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "coxg65IBzFoC"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.fit(x_train, y_train, epochs=4)\n",
        "#Fix error"
      ],
      "metadata": {
        "id": "qypjj4DYxaOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In transfer learning if the input features of your task don't have the same size like the one of the original model then you have to add a preprocessing step to resize the size of your images to be closer to the one of the original task. The output layer of the original model should always be replaced since they might not have the intented number of output as the original task. The upper hidden layers are less likely to be useful as the lower hidden layers since the task might differ significantly from the ones that were most useful."
      ],
      "metadata": {
        "id": "JIzo5V1rdghK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=[28,28]),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(300,kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "tf.keras.layers.Activation(\"elu\"),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dense(1,activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "W_ZDTSNczb-Z"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "n2n0nRe5kiBc"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "zSlZ9iZ3k3Qj",
        "outputId": "29133668-109e-4a8e-a2c6-c66ab5b9e683"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-0a973205d825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 28, 28)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cb = tf.keras.callbacks.ModelCheckpoint(save) DO SAVING THE MODEL ONCE AGAIN "
      ],
      "metadata": {
        "id": "T6w-EMihlreS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"MyModel.H5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RcOIBkelb0Y",
        "outputId": "9841b0ee-5928-4f9c-ba60-617bbc471803"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: MyModel.H5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We load the model \n",
        "model_A = tf.keras.models.load_model(\"MyModel.H5\")"
      ],
      "metadata": {
        "id": "H2aWLXdemnzA"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We create a new model based on the layers of the loaded model \n",
        "model_A_reloaded = tf.keras.models.Sequential(model_A.layers[:-1]) #We also remove the last layer of this model since the  task is different from the original one which means the output layer should have different number of neurons\n",
        " "
      ],
      "metadata": {
        "id": "pGg8r8Lem58z"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We add our own output layer\n",
        "model_A_reloaded.add(tf.keras.layers.Dense(1, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "iLLZCe5moCsx"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cloning the model \n",
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "#This clone comes without parameters so we set them \n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ],
      "metadata": {
        "id": "3CuUpr90oTFo"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We freeze the layers \n",
        "for layer in model_A_clone.layers[:-1]: #To freeze the layers we set every layers trainable attributes to false\n",
        "  layer.trainable = False "
      ],
      "metadata": {
        "id": "9j7cHBybpCWG"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "VnmLBFotqOSA"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OUwRe1E_2bZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We should compile the model after we freeze of unfreeze a particular layer\n",
        "\n"
      ],
      "metadata": {
        "id": "msboPW7Vqsgv"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.fit(x_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "UR_emLz1sHGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnistOne= tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "cfFpnz73q4yD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_full,x_test),(y_train_full, y_test) = mnistOne"
      ],
      "metadata": {
        "id": "I5AQ3bJJrOYh"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0YWuTetrdoj",
        "outputId": "8ed82159-5ee7-4cdf-c1b0-d66e3063c7fe"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnistOne = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "VHCQFdRAydvV"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_full, x_test),(y_train_full, y_test) = mnistOne"
      ],
      "metadata": {
        "id": "QhfgWCvWynUA"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJzKm_lvzu4q",
        "outputId": "07b19c73-5d6f-4181-a964-c9352391ab48"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmQXZ5y6zwYQ",
        "outputId": "ed16e377-3dd2-4869-c1a1-dc12a98e8ed2"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_valid = x_train_full[:5000], x_train_full[:5000]\n",
        "y_train,y_valid = y_train_full[:5000], y_train_full[:5000]"
      ],
      "metadata": {
        "id": "o89pFG1AzU2u"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj4dfFyx4t1e",
        "outputId": "f764c467-0b05-4845-f4ac-0ef52d77121a"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 28, 28), (5000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.compile(loss=tf.keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "3Rk__oqpzVLb"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.fit(x_train,y_train,epochs=5, validation_data=[x_valid, y_valid])"
      ],
      "metadata": {
        "id": "mDm7Th8S1CGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_clone.summary()"
      ],
      "metadata": {
        "id": "pjPrrYE014th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0kVtIC9G2BI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}