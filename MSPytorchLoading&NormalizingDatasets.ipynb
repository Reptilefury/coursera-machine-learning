{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSPytorchLoading&NormalizingDatasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7qatYnyQC9rXKw/ZXyDg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/MSPytorchLoading%26NormalizingDatasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code for loading and preprocessing our dataset can get hard and messy to maintain so we want this code to be docoupled from our model training code for easier readability and maintanance and modularity. Pytorch provides two data primitives that allow us to load preloaded datasets as well as our own datasets. These primitives include:\n",
        "torch.utils.data.DataLoader and torch.utils.data.Dataset. The dataset stores the samples and their corresponding labels. DataLoader wraps an iterable around the dataset for an easy access to the data. Pytorch libraries have preloaded datasets that can be used for prototyping, these datasets subclass\n",
        "torch.utils.data.Datasets"
      ],
      "metadata": {
        "id": "A93NiJx909S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a dataset, loading a Fashion Mnist from torchVision. Fashion Mnist is a zalando dataset consiting of 60,000 training examples and 10,000 test examples. Each image is a 2D arrya of grey scale image(One channel no RGB) of 28 by 28  for both width and height which a total of 784 pixels. Each image corresponds to the respective label among the 10 classes with include: T-shirt, Trouser, Pullover, Dress, Bag, Ankle-Boot and so on. The gray scale value range from 0  to 255 , in this case a value of 0 would be white while a black color would be 255. "
      ],
      "metadata": {
        "id": "JrXccB_S5u7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameters for loading  Fashion Mnist dataset are:\n",
        "Root,Train, Download and Transform.\n",
        "Root = The path where our dataset would be stored, Download takes a boolean value which specifies to download the dataset from the internet if the dataset is not available on the root path. Train takes a boolean value which specifies whether the dataset should be a training set. Transform and target_transform specify the features and labels"
      ],
      "metadata": {
        "id": "T3ateQld8uH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ge9m4rinyXn6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch "
      ],
      "metadata": {
        "id": "fdVA4wnqBiDJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True, \n",
        "    download=True, \n",
        "    transform=ToTensor())"
      ],
      "metadata": {
        "id": "_jbaXSBO_1SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor())"
      ],
      "metadata": {
        "id": "KLKinbkJA8Gq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor,Lambda\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Iq2O2oSBBcSO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We load the training data which takes theses parameters root, train ,download and transform\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor())"
      ],
      "metadata": {
        "id": "DlyfUppdFa6W"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data\n",
        "testing_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor())"
      ],
      "metadata": {
        "id": "nMlE5e2ZGHQn"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}