{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro for experts.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrxqv5GMFwFafIHbOtO+nA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/Intro_for_experts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dfNqNgIW-ITr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data set \n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "#Split the dataset \n",
        "(train_images,train_labels),(test_images,test_labels) = mnist\n",
        "\n",
        "#Standardize/ normalize the data \n",
        "train_images,test_images = train_images/255.0,test_images/255.0 \n",
        "\n",
        "#Add a channels dimension \n",
        "train_images = train_images[..., tf.newaxis].astype('float32')\n",
        "test_images = test_images[...,tf.newaxis].astype('float32')"
      ],
      "metadata": {
        "id": "No84z6R4AIN-"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch and shuffle the dataset \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)).shuffle(10000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)"
      ],
      "metadata": {
        "id": "ehooVwUpAffH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model using the subclassing API\n",
        "class MyModel(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "    self.Conv1 = tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\")\n",
        "    self.MaxPool = tf.keras.layers.MaxPool2D((2,2))\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.Dense1 = tf.keras.layers.Dense(128,activation = \"relu\")\n",
        "    self.Output = tf.keras.layers.Dense(10,)#activation =\"softmax\")\n",
        "  \n",
        "  def call(self,x):\n",
        "    x = self.Conv1(x) \n",
        "    x = self.MaxPool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.Dense1(x)\n",
        "    x = self.Output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "jBgG8kY7CjHM"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()"
      ],
      "metadata": {
        "id": "TUpYFCbeHdKI"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the hyperparameters\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "accuracy = tf.keras.metrics.Accuracy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Ui_-rGQnHiEc"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selects the metrics to measure the loss and accuracy of the model"
      ],
      "metadata": {
        "id": "gvcwtfjzIIKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Metrics to measure the loss and accuracy of the model\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = \"train_accuracy\")\n",
        "\n",
        "#test loss and accuracy \n",
        "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test-accuracy\")"
      ],
      "metadata": {
        "id": "OvCIJC03H2gM"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using tf.Gradient Tape to Train the model \n",
        "@tf.function #Converts a regular python function to a tensorflow graph function \n",
        "def train_step(images,labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    #Training = true is there are  layers with different behaviour during training versus inference such as Dropout\n",
        "    predictions = model(images, training =True)\n",
        "    #Calculate the loss \n",
        "    loss = loss_fn(labels,predictions)\n",
        "    gradient = tape.gradient(loss,model.trainable_variables) #Get the gradient of the loss function \n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables)) #Update the parameters based on the gradient of the loss \n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels,predictions)"
      ],
      "metadata": {
        "id": "PinVMMUgKVz2"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model"
      ],
      "metadata": {
        "id": "rgdEYxnpOG5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  #Training = false is only needed if there are layers with different behaviours\n",
        "  #during training versus inference \n",
        "  predictions = model(images,training=False)\n",
        "  t_loss = loss_fn(predictions,labels)  \n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels,predictions)"
      ],
      "metadata": {
        "id": "hksyHCWOEOTt"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10 \n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  #Reset the metrics at the start of the next epoch \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  #for image,labels in train_dataset:\n",
        "   # train_step(image,labels)\n",
        "  \n",
        "  for test_images,test_labels in  test_dataset:\n",
        "    test_step(test_images,test_labels)\n",
        "    \n",
        "  print(f\"Epoch:{epoch + 1}/n\",\n",
        "        f\"train_loss {train_loss.result()}/n\",\n",
        "        f\"Accuracy{train_accuracy.result() * 100}/n\",\n",
        "        f\"Test_loss {test_loss.result()}/n\",\n",
        "        f\"Test_accuracy {test_accuracy.result()}/n\"\n",
        "        )\n",
        "  #print(f\"train_loss {train_loss.result()}\")\n",
        "  #print(f\"\")"
      ],
      "metadata": {
        "id": "3UMTgTkUACRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Hf6-jojU_Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wRBa_25iU7q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xRHWT4EsUJoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WWLhplLgUO_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I3DJthYIUPDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}