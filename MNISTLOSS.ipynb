{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/MNISTLOSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSWZDSApxURs"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq fastbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICEKDz0Mwu-0"
      },
      "outputs": [],
      "source": [
        "import fastbook\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fastbook.setup_book()"
      ],
      "metadata": {
        "id": "QpZtubkpeqFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastbook import *"
      ],
      "metadata": {
        "id": "Rn011dfye48Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "uUDMuJxXfDdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-SPkEcYFfJWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "F9qXl0jSfK-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ],
      "metadata": {
        "id": "mqvW74jhfOck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threes = (path/'train'/'3').ls()"
      ],
      "metadata": {
        "id": "qBy_7n08fS30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sevens = (path/'train'/'7').ls()"
      ],
      "metadata": {
        "id": "pMmBTDRufY0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image_threes = Image.open(threes[0])"
      ],
      "metadata": {
        "id": "qWtmFBQefb_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image_threes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "ERbkpiSRgAtO",
        "outputId": "9d19228d-0444-4379-bcee-423da6f89c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAUlEQVR4nGNgGGSAkYGBgeWgFcPmCwwMz+b//oehgO3HXyhYksrLjKaTwcaYgcFPj4GBgY+FoWrqFxyWBPT++LuSGYckA0PA47/ZcA4TmuSebwwPMB2lxsDAwKDUe/jvAW64IAuUzq/dw8DAYCPMwNDzFUOS9bs/lOX65twvZK8wMDAwaEsySCcwMDCYcDFMqPiNw7nGB/7+7WPBIckgevDv31xckgwir/6uRfMh7xQZGHP337+sqJIT/gbAmFkwSbj+hwh1Bhg2qf192wsxWOv930kQH8L9yayyWfnz3McMDLphXOcbtqDrVVwIjfIzPlj8wMSa8ujv3wuN/FjkqAkAzxxU3w6Du0AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F543548D890>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image_sevens = Image.open(sevens[0])"
      ],
      "metadata": {
        "id": "z0-d0eRigEVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image_sevens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "NSeGO-3YgKjc",
        "outputId": "75f506f0-5943-4883-d39a-0124cf9243d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAcElEQVR4nN2QsRHAMAwCKTKYshmZjNFIYV98F0lOHxoVf4Ak4J8KKwAgGAWzTYZtJUg/YoK2NWFiso2gPZvfjfGMbNTIzoyDqdoUkDkWzsbVm69Yx7RGbYws/7ZCW6aPTTvfjkF9Zv22Y84LONvUUjdhiGrjCvortAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F543548DD10>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threes_tensors = [tensor(Image.open(o))for o in(threes)]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iHJJod8lgMke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im3_t = threes_tensors[0]"
      ],
      "metadata": {
        "id": "LhX9MdMVhNLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im3_t"
      ],
      "metadata": {
        "id": "RAxr5nbihrPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42817728-dc78-47da-de6b-4bc3ecea23d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   4, 197, 255, 255, 178, 130, 130, 130, 104,   7,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   6, 248, 253, 253, 253, 253, 253, 253, 253, 253, 164, 101,  13,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  60, 111, 111, 111, 189, 235, 235, 235, 235, 249, 253, 253, 119,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  80, 141, 248, 253, 169,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  80, 227, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12, 217, 253,  75,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   6,  38,   0,   0,   0,   0,  34, 141, 195, 253, 192,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0, 117, 242, 174, 174, 174, 174, 234, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0, 122, 233, 253, 253, 253, 253, 253, 253, 253, 253, 145,  56,   6,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  43,  68,  68,  95, 191, 191, 191, 191, 243, 253, 253, 141,   5,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 192, 253, 253, 142,   4,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 193, 253, 253, 109,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 234, 253, 173,   2,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  13, 148,  28,   0,   0,   0,   0,   0,   0,   0,   0, 187, 253, 253,   5,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0, 144, 253,  80,   0,   0,   0,   0,   0,   0,   0,   0, 106, 253, 253,   5,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0, 113, 253,  80,   0,   0,   0,   0,   0,   0,   0,   0, 154, 253, 253,   5,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  38, 253, 237, 141,  28,   0,   0,   0,   0,   0,  42, 239, 253, 146,   1,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   3,  39, 218, 253, 240, 141, 112, 112, 112, 157, 243, 253, 204,  76,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  33, 161, 253, 253, 253, 253, 253, 253, 253, 204,  76,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   5, 100, 226, 253, 253, 208, 129,  15,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(im3_t[4:10, 4:22])"
      ],
      "metadata": {
        "id": "Ud78qOJnht7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sevens_tensors = [tensor(Image.open(o)) for o in sevens]"
      ],
      "metadata": {
        "id": "Q3H0yEAhh3Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im7_t = sevens_tensors[0]"
      ],
      "metadata": {
        "id": "ebQy5OHTiGq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im7_t"
      ],
      "metadata": {
        "id": "ESKGp0UdiLH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90509fbe-cf4a-4caf-84af-8f2e7ccae9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 191,  64,   0,   0,   0,   0,  64, 128,  64,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255, 255, 128, 128,  64, 255, 255, 255, 191,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 128,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 191, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 255,   0,  64, 128, 255, 255, 255, 191,  64,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255,  64,   0,   0,  64, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 191,   0,   0,   0, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0, 128, 255, 255, 191,   0,   0,   0, 191, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 128,   0,   0, 128, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 255, 128,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 255, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  64, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0, 191, 255, 255,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0, 191, 255, 255, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  64, 191, 191,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(im7_t[10:20,7:27])"
      ],
      "metadata": {
        "id": "YRnsRXC9iMvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We color code our tensor images\n",
        "df.style.set_properties(**{'font - size':'6pt'}).background_gradient('Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "bRPIj-rjiTpc",
        "outputId": "f7cc4e46-d603-4a6e-9af4-6f961998c7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_ad64f_row0_col0, #T_ad64f_row0_col1, #T_ad64f_row0_col2, #T_ad64f_row0_col3, #T_ad64f_row0_col15, #T_ad64f_row0_col16, #T_ad64f_row0_col17, #T_ad64f_row0_col18, #T_ad64f_row0_col19, #T_ad64f_row1_col0, #T_ad64f_row1_col1, #T_ad64f_row1_col2, #T_ad64f_row1_col7, #T_ad64f_row1_col15, #T_ad64f_row1_col16, #T_ad64f_row1_col17, #T_ad64f_row1_col18, #T_ad64f_row1_col19, #T_ad64f_row2_col0, #T_ad64f_row2_col1, #T_ad64f_row2_col7, #T_ad64f_row2_col8, #T_ad64f_row2_col14, #T_ad64f_row2_col15, #T_ad64f_row2_col16, #T_ad64f_row2_col17, #T_ad64f_row2_col18, #T_ad64f_row2_col19, #T_ad64f_row3_col0, #T_ad64f_row3_col1, #T_ad64f_row3_col6, #T_ad64f_row3_col7, #T_ad64f_row3_col8, #T_ad64f_row3_col13, #T_ad64f_row3_col14, #T_ad64f_row3_col15, #T_ad64f_row3_col16, #T_ad64f_row3_col17, #T_ad64f_row3_col18, #T_ad64f_row3_col19, #T_ad64f_row4_col0, #T_ad64f_row4_col5, #T_ad64f_row4_col6, #T_ad64f_row4_col7, #T_ad64f_row4_col12, #T_ad64f_row4_col13, #T_ad64f_row4_col14, #T_ad64f_row4_col15, #T_ad64f_row4_col16, #T_ad64f_row4_col17, #T_ad64f_row4_col18, #T_ad64f_row4_col19, #T_ad64f_row5_col0, #T_ad64f_row5_col1, #T_ad64f_row5_col5, #T_ad64f_row5_col6, #T_ad64f_row5_col12, #T_ad64f_row5_col13, #T_ad64f_row5_col14, #T_ad64f_row5_col15, #T_ad64f_row5_col16, #T_ad64f_row5_col17, #T_ad64f_row5_col18, #T_ad64f_row5_col19, #T_ad64f_row6_col0, #T_ad64f_row6_col1, #T_ad64f_row6_col2, #T_ad64f_row6_col3, #T_ad64f_row6_col4, #T_ad64f_row6_col5, #T_ad64f_row6_col11, #T_ad64f_row6_col12, #T_ad64f_row6_col13, #T_ad64f_row6_col14, #T_ad64f_row6_col15, #T_ad64f_row6_col16, #T_ad64f_row6_col17, #T_ad64f_row6_col18, #T_ad64f_row6_col19, #T_ad64f_row7_col0, #T_ad64f_row7_col1, #T_ad64f_row7_col2, #T_ad64f_row7_col3, #T_ad64f_row7_col4, #T_ad64f_row7_col5, #T_ad64f_row7_col11, #T_ad64f_row7_col12, #T_ad64f_row7_col13, #T_ad64f_row7_col14, #T_ad64f_row7_col15, #T_ad64f_row7_col16, #T_ad64f_row7_col17, #T_ad64f_row7_col18, #T_ad64f_row7_col19, #T_ad64f_row8_col0, #T_ad64f_row8_col1, #T_ad64f_row8_col2, #T_ad64f_row8_col3, #T_ad64f_row8_col4, #T_ad64f_row8_col10, #T_ad64f_row8_col11, #T_ad64f_row8_col12, #T_ad64f_row8_col13, #T_ad64f_row8_col14, #T_ad64f_row8_col15, #T_ad64f_row8_col16, #T_ad64f_row8_col17, #T_ad64f_row8_col18, #T_ad64f_row8_col19, #T_ad64f_row9_col0, #T_ad64f_row9_col1, #T_ad64f_row9_col2, #T_ad64f_row9_col3, #T_ad64f_row9_col9, #T_ad64f_row9_col10, #T_ad64f_row9_col11, #T_ad64f_row9_col12, #T_ad64f_row9_col13, #T_ad64f_row9_col14, #T_ad64f_row9_col15, #T_ad64f_row9_col16, #T_ad64f_row9_col17, #T_ad64f_row9_col18, #T_ad64f_row9_col19 {\n",
              "  font - size: 6pt;\n",
              "  background-color: #ffffff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ad64f_row0_col4, #T_ad64f_row0_col5, #T_ad64f_row0_col6, #T_ad64f_row0_col8, #T_ad64f_row0_col9, #T_ad64f_row0_col10, #T_ad64f_row0_col11, #T_ad64f_row0_col12, #T_ad64f_row0_col13, #T_ad64f_row0_col14, #T_ad64f_row1_col4, #T_ad64f_row1_col5, #T_ad64f_row1_col6, #T_ad64f_row1_col10, #T_ad64f_row1_col11, #T_ad64f_row1_col12, #T_ad64f_row2_col3, #T_ad64f_row2_col4, #T_ad64f_row2_col5, #T_ad64f_row2_col10, #T_ad64f_row2_col11, #T_ad64f_row2_col12, #T_ad64f_row3_col3, #T_ad64f_row3_col4, #T_ad64f_row3_col9, #T_ad64f_row3_col10, #T_ad64f_row3_col11, #T_ad64f_row4_col1, #T_ad64f_row4_col2, #T_ad64f_row4_col3, #T_ad64f_row4_col9, #T_ad64f_row4_col10, #T_ad64f_row5_col3, #T_ad64f_row5_col8, #T_ad64f_row5_col9, #T_ad64f_row5_col10, #T_ad64f_row6_col7, #T_ad64f_row6_col8, #T_ad64f_row6_col9, #T_ad64f_row7_col6, #T_ad64f_row7_col7, #T_ad64f_row7_col8, #T_ad64f_row7_col9, #T_ad64f_row8_col6, #T_ad64f_row8_col7, #T_ad64f_row8_col8, #T_ad64f_row9_col5, #T_ad64f_row9_col6, #T_ad64f_row9_col7 {\n",
              "  font - size: 6pt;\n",
              "  background-color: #000000;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ad64f_row0_col7, #T_ad64f_row1_col3, #T_ad64f_row1_col13, #T_ad64f_row3_col2, #T_ad64f_row3_col5, #T_ad64f_row4_col4, #T_ad64f_row4_col8, #T_ad64f_row4_col11, #T_ad64f_row5_col2, #T_ad64f_row8_col5, #T_ad64f_row9_col8 {\n",
              "  font - size: 6pt;\n",
              "  background-color: #525252;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_ad64f_row1_col8, #T_ad64f_row1_col14, #T_ad64f_row2_col2, #T_ad64f_row2_col6, #T_ad64f_row2_col9, #T_ad64f_row2_col13, #T_ad64f_row3_col12, #T_ad64f_row5_col11, #T_ad64f_row6_col6, #T_ad64f_row7_col10 {\n",
              "  font - size: 6pt;\n",
              "  background-color: #d9d9d9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_ad64f_row1_col9, #T_ad64f_row5_col4, #T_ad64f_row5_col7, #T_ad64f_row6_col10, #T_ad64f_row8_col9, #T_ad64f_row9_col4 {\n",
              "  font - size: 6pt;\n",
              "  background-color: #959595;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ad64f_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >0</th>\n",
              "      <th class=\"col_heading level0 col1\" >1</th>\n",
              "      <th class=\"col_heading level0 col2\" >2</th>\n",
              "      <th class=\"col_heading level0 col3\" >3</th>\n",
              "      <th class=\"col_heading level0 col4\" >4</th>\n",
              "      <th class=\"col_heading level0 col5\" >5</th>\n",
              "      <th class=\"col_heading level0 col6\" >6</th>\n",
              "      <th class=\"col_heading level0 col7\" >7</th>\n",
              "      <th class=\"col_heading level0 col8\" >8</th>\n",
              "      <th class=\"col_heading level0 col9\" >9</th>\n",
              "      <th class=\"col_heading level0 col10\" >10</th>\n",
              "      <th class=\"col_heading level0 col11\" >11</th>\n",
              "      <th class=\"col_heading level0 col12\" >12</th>\n",
              "      <th class=\"col_heading level0 col13\" >13</th>\n",
              "      <th class=\"col_heading level0 col14\" >14</th>\n",
              "      <th class=\"col_heading level0 col15\" >15</th>\n",
              "      <th class=\"col_heading level0 col16\" >16</th>\n",
              "      <th class=\"col_heading level0 col17\" >17</th>\n",
              "      <th class=\"col_heading level0 col18\" >18</th>\n",
              "      <th class=\"col_heading level0 col19\" >19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_ad64f_row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col2\" class=\"data row0 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col4\" class=\"data row0 col4\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col5\" class=\"data row0 col5\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col6\" class=\"data row0 col6\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col7\" class=\"data row0 col7\" >191</td>\n",
              "      <td id=\"T_ad64f_row0_col8\" class=\"data row0 col8\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col9\" class=\"data row0 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col10\" class=\"data row0 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col11\" class=\"data row0 col11\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col12\" class=\"data row0 col12\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col13\" class=\"data row0 col13\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col14\" class=\"data row0 col14\" >255</td>\n",
              "      <td id=\"T_ad64f_row0_col15\" class=\"data row0 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col16\" class=\"data row0 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col17\" class=\"data row0 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col18\" class=\"data row0 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row0_col19\" class=\"data row0 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_ad64f_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col2\" class=\"data row1 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col3\" class=\"data row1 col3\" >191</td>\n",
              "      <td id=\"T_ad64f_row1_col4\" class=\"data row1 col4\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col5\" class=\"data row1 col5\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col6\" class=\"data row1 col6\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col7\" class=\"data row1 col7\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col8\" class=\"data row1 col8\" >64</td>\n",
              "      <td id=\"T_ad64f_row1_col9\" class=\"data row1 col9\" >128</td>\n",
              "      <td id=\"T_ad64f_row1_col10\" class=\"data row1 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col11\" class=\"data row1 col11\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col12\" class=\"data row1 col12\" >255</td>\n",
              "      <td id=\"T_ad64f_row1_col13\" class=\"data row1 col13\" >191</td>\n",
              "      <td id=\"T_ad64f_row1_col14\" class=\"data row1 col14\" >64</td>\n",
              "      <td id=\"T_ad64f_row1_col15\" class=\"data row1 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col16\" class=\"data row1 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col17\" class=\"data row1 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col18\" class=\"data row1 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row1_col19\" class=\"data row1 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_ad64f_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col2\" class=\"data row2 col2\" >64</td>\n",
              "      <td id=\"T_ad64f_row2_col3\" class=\"data row2 col3\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col4\" class=\"data row2 col4\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col5\" class=\"data row2 col5\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col6\" class=\"data row2 col6\" >64</td>\n",
              "      <td id=\"T_ad64f_row2_col7\" class=\"data row2 col7\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col8\" class=\"data row2 col8\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col9\" class=\"data row2 col9\" >64</td>\n",
              "      <td id=\"T_ad64f_row2_col10\" class=\"data row2 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col11\" class=\"data row2 col11\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col12\" class=\"data row2 col12\" >255</td>\n",
              "      <td id=\"T_ad64f_row2_col13\" class=\"data row2 col13\" >64</td>\n",
              "      <td id=\"T_ad64f_row2_col14\" class=\"data row2 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col15\" class=\"data row2 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col16\" class=\"data row2 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col17\" class=\"data row2 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col18\" class=\"data row2 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row2_col19\" class=\"data row2 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_ad64f_row3_col0\" class=\"data row3 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col2\" class=\"data row3 col2\" >191</td>\n",
              "      <td id=\"T_ad64f_row3_col3\" class=\"data row3 col3\" >255</td>\n",
              "      <td id=\"T_ad64f_row3_col4\" class=\"data row3 col4\" >255</td>\n",
              "      <td id=\"T_ad64f_row3_col5\" class=\"data row3 col5\" >191</td>\n",
              "      <td id=\"T_ad64f_row3_col6\" class=\"data row3 col6\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col7\" class=\"data row3 col7\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col8\" class=\"data row3 col8\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col9\" class=\"data row3 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row3_col10\" class=\"data row3 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row3_col11\" class=\"data row3 col11\" >255</td>\n",
              "      <td id=\"T_ad64f_row3_col12\" class=\"data row3 col12\" >64</td>\n",
              "      <td id=\"T_ad64f_row3_col13\" class=\"data row3 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col14\" class=\"data row3 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col15\" class=\"data row3 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col16\" class=\"data row3 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col17\" class=\"data row3 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col18\" class=\"data row3 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row3_col19\" class=\"data row3 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_ad64f_row4_col0\" class=\"data row4 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col1\" class=\"data row4 col1\" >128</td>\n",
              "      <td id=\"T_ad64f_row4_col2\" class=\"data row4 col2\" >255</td>\n",
              "      <td id=\"T_ad64f_row4_col3\" class=\"data row4 col3\" >255</td>\n",
              "      <td id=\"T_ad64f_row4_col4\" class=\"data row4 col4\" >191</td>\n",
              "      <td id=\"T_ad64f_row4_col5\" class=\"data row4 col5\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col6\" class=\"data row4 col6\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col7\" class=\"data row4 col7\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col8\" class=\"data row4 col8\" >191</td>\n",
              "      <td id=\"T_ad64f_row4_col9\" class=\"data row4 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row4_col10\" class=\"data row4 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row4_col11\" class=\"data row4 col11\" >191</td>\n",
              "      <td id=\"T_ad64f_row4_col12\" class=\"data row4 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col13\" class=\"data row4 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col14\" class=\"data row4 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col15\" class=\"data row4 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col16\" class=\"data row4 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col17\" class=\"data row4 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col18\" class=\"data row4 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row4_col19\" class=\"data row4 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_ad64f_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col2\" class=\"data row5 col2\" >191</td>\n",
              "      <td id=\"T_ad64f_row5_col3\" class=\"data row5 col3\" >255</td>\n",
              "      <td id=\"T_ad64f_row5_col4\" class=\"data row5 col4\" >128</td>\n",
              "      <td id=\"T_ad64f_row5_col5\" class=\"data row5 col5\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col6\" class=\"data row5 col6\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col7\" class=\"data row5 col7\" >128</td>\n",
              "      <td id=\"T_ad64f_row5_col8\" class=\"data row5 col8\" >255</td>\n",
              "      <td id=\"T_ad64f_row5_col9\" class=\"data row5 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row5_col10\" class=\"data row5 col10\" >255</td>\n",
              "      <td id=\"T_ad64f_row5_col11\" class=\"data row5 col11\" >64</td>\n",
              "      <td id=\"T_ad64f_row5_col12\" class=\"data row5 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col13\" class=\"data row5 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col14\" class=\"data row5 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col15\" class=\"data row5 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col16\" class=\"data row5 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col17\" class=\"data row5 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col18\" class=\"data row5 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row5_col19\" class=\"data row5 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_ad64f_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col1\" class=\"data row6 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col2\" class=\"data row6 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col3\" class=\"data row6 col3\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col4\" class=\"data row6 col4\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col5\" class=\"data row6 col5\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col6\" class=\"data row6 col6\" >64</td>\n",
              "      <td id=\"T_ad64f_row6_col7\" class=\"data row6 col7\" >255</td>\n",
              "      <td id=\"T_ad64f_row6_col8\" class=\"data row6 col8\" >255</td>\n",
              "      <td id=\"T_ad64f_row6_col9\" class=\"data row6 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row6_col10\" class=\"data row6 col10\" >128</td>\n",
              "      <td id=\"T_ad64f_row6_col11\" class=\"data row6 col11\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col12\" class=\"data row6 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col13\" class=\"data row6 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col14\" class=\"data row6 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col15\" class=\"data row6 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col16\" class=\"data row6 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col17\" class=\"data row6 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col18\" class=\"data row6 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row6_col19\" class=\"data row6 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_ad64f_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col2\" class=\"data row7 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col3\" class=\"data row7 col3\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col4\" class=\"data row7 col4\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col5\" class=\"data row7 col5\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col6\" class=\"data row7 col6\" >255</td>\n",
              "      <td id=\"T_ad64f_row7_col7\" class=\"data row7 col7\" >255</td>\n",
              "      <td id=\"T_ad64f_row7_col8\" class=\"data row7 col8\" >255</td>\n",
              "      <td id=\"T_ad64f_row7_col9\" class=\"data row7 col9\" >255</td>\n",
              "      <td id=\"T_ad64f_row7_col10\" class=\"data row7 col10\" >64</td>\n",
              "      <td id=\"T_ad64f_row7_col11\" class=\"data row7 col11\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col12\" class=\"data row7 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col13\" class=\"data row7 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col14\" class=\"data row7 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col15\" class=\"data row7 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col16\" class=\"data row7 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col17\" class=\"data row7 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col18\" class=\"data row7 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row7_col19\" class=\"data row7 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_ad64f_row8_col0\" class=\"data row8 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col1\" class=\"data row8 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col2\" class=\"data row8 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col3\" class=\"data row8 col3\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col4\" class=\"data row8 col4\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col5\" class=\"data row8 col5\" >191</td>\n",
              "      <td id=\"T_ad64f_row8_col6\" class=\"data row8 col6\" >255</td>\n",
              "      <td id=\"T_ad64f_row8_col7\" class=\"data row8 col7\" >255</td>\n",
              "      <td id=\"T_ad64f_row8_col8\" class=\"data row8 col8\" >255</td>\n",
              "      <td id=\"T_ad64f_row8_col9\" class=\"data row8 col9\" >128</td>\n",
              "      <td id=\"T_ad64f_row8_col10\" class=\"data row8 col10\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col11\" class=\"data row8 col11\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col12\" class=\"data row8 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col13\" class=\"data row8 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col14\" class=\"data row8 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col15\" class=\"data row8 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col16\" class=\"data row8 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col17\" class=\"data row8 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col18\" class=\"data row8 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row8_col19\" class=\"data row8 col19\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ad64f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_ad64f_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col2\" class=\"data row9 col2\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col3\" class=\"data row9 col3\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col4\" class=\"data row9 col4\" >128</td>\n",
              "      <td id=\"T_ad64f_row9_col5\" class=\"data row9 col5\" >255</td>\n",
              "      <td id=\"T_ad64f_row9_col6\" class=\"data row9 col6\" >255</td>\n",
              "      <td id=\"T_ad64f_row9_col7\" class=\"data row9 col7\" >255</td>\n",
              "      <td id=\"T_ad64f_row9_col8\" class=\"data row9 col8\" >191</td>\n",
              "      <td id=\"T_ad64f_row9_col9\" class=\"data row9 col9\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col10\" class=\"data row9 col10\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col11\" class=\"data row9 col11\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col12\" class=\"data row9 col12\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col13\" class=\"data row9 col13\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col14\" class=\"data row9 col14\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col15\" class=\"data row9 col15\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col16\" class=\"data row9 col16\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col17\" class=\"data row9 col17\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col18\" class=\"data row9 col18\" >0</td>\n",
              "      <td id=\"T_ad64f_row9_col19\" class=\"data row9 col19\" >0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f54391fdb90>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "f0ndUn-4injH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we turn the tensors into a stack and turn them into floating point numbers between 0  and 1  through calling the .float()method and dividing by 255\n",
        "sevens_stack = torch.stack(sevens_tensors).float() /255"
      ],
      "metadata": {
        "id": "U2chjkhckCi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threes_stack = torch.stack(threes_tensors).float() /255"
      ],
      "metadata": {
        "id": "gD_vHwIQkv6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sevens_stack[0]"
      ],
      "metadata": {
        "id": "WDuQraCOlJg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492c7c49-d3ff-4c6c-99b4-4a4d72266c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 0.7490, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 0.5020, 0.2510, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 1.0000, 0.5020, 0.5020, 0.2510, 1.0000, 1.0000, 1.0000, 0.7490, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.7490, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 0.0000, 0.2510, 0.5020, 1.0000, 1.0000, 1.0000, 0.7490, 0.2510, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 0.5020, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000, 1.0000, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 0.7490, 0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_3_tens = torch.stack(threes_tensors).float() /255"
      ],
      "metadata": {
        "id": "KaHFz7cclfVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_7_tens = torch.stack(sevens_tensors).float() /255"
      ],
      "metadata": {
        "id": "8xyrlakSmBtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data processing with pytorch we take the data and turn the shape without changing the contents of the data\n",
        "train_x = torch.cat([threes_stack, sevens_stack]).view(-1,28*28) "
      ],
      "metadata": {
        "id": "qyPIEKkdmVs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We label each image\n",
        "train_y = tensor([1] * len(threes) + [0] * len(sevens)).unsqueeze(1)"
      ],
      "metadata": {
        "id": "IloGvMN5nbzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dset = list(zip(train_x, train_y))"
      ],
      "metadata": {
        "id": "Jmq7DxQqotoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing the validation data\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28 * 28 )"
      ],
      "metadata": {
        "id": "vBNm9_xCpQlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_y = tensor([1] * len(valid_3_tens) + [0] * len(valid_7_tens)).unsqueeze(1)"
      ],
      "metadata": {
        "id": "uut0agE5qJ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validDset = list(zip(valid_x,valid_y))"
      ],
      "metadata": {
        "id": "VUg2FYYgqmeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dset[0]\n"
      ],
      "metadata": {
        "id": "ri4keFchqrci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63081ec7-3ec7-452e-ea55-7141518f7bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
              "         0.7725, 1.0000, 1.0000, 0.6980, 0.5098, 0.5098, 0.5098, 0.4078, 0.0275, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0235, 0.9725, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.6431, 0.3961, 0.0510, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.4353, 0.4353, 0.4353, 0.7412, 0.9216, 0.9216, 0.9216, 0.9216, 0.9765, 0.9922, 0.9922, 0.4667, 0.0471, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.5529, 0.9725,\n",
              "         0.9922, 0.6627, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3137, 0.8902, 0.9922, 0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.8510, 0.9922, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0235, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.5529, 0.7647, 0.9922, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9490, 0.6824, 0.6824, 0.6824, 0.6824, 0.9176, 0.9922, 0.9922, 0.9922, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4784, 0.9137, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.5686, 0.2196, 0.0235,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.2667, 0.2667, 0.3725, 0.7490, 0.7490, 0.7490, 0.7490,\n",
              "         0.9529, 0.9922, 0.9922, 0.5529, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.7529, 0.9922, 0.9922, 0.5569, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.7569, 0.9922, 0.9922, 0.4275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.9176, 0.9922, 0.6784, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.5804, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7333, 0.9922, 0.9922, 0.0196, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 0.9922, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4157,\n",
              "         0.9922, 0.9922, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4431, 0.9922, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.6039, 0.9922, 0.9922, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9922, 0.9294, 0.5529,\n",
              "         0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1647, 0.9373, 0.9922, 0.5725, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0118, 0.1529, 0.8549, 0.9922, 0.9412, 0.5529, 0.4392, 0.4392, 0.4392, 0.6157, 0.9529, 0.9922, 0.8000, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.6314, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8000, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0196, 0.3922, 0.8863, 0.9922, 0.9922, 0.8157, 0.5059, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]),\n",
              " tensor([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We then randomly initialize our weights from random numbers to start training at a point\n",
        "#Otherwise if we don't our model will give us constant values which won't affect backpropagation hence the model won't learn\n",
        "def init_params(size,std=1.0):\n",
        "  return (torch.randn(size)*std).requires_grad_()\n"
      ],
      "metadata": {
        "id": "OJFdQ25fq7SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = init_params((28*28,1))"
      ],
      "metadata": {
        "id": "1oaUivwasL5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "id": "0QJZZMz7saw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2ecbca-a87f-42e4-8501-5b656d96a6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.5584e-01],\n",
              "        [ 9.0406e-01],\n",
              "        [-5.6593e-01],\n",
              "        [ 3.8410e-01],\n",
              "        [-7.8158e-01],\n",
              "        [-1.5094e-01],\n",
              "        [ 4.1993e-01],\n",
              "        [ 1.4059e+00],\n",
              "        [-8.2709e-01],\n",
              "        [ 1.5608e+00],\n",
              "        [-1.0952e+00],\n",
              "        [ 1.1855e+00],\n",
              "        [ 1.1881e+00],\n",
              "        [ 2.0556e+00],\n",
              "        [ 6.6027e-01],\n",
              "        [-1.1078e+00],\n",
              "        [-2.9196e-01],\n",
              "        [ 4.5644e-01],\n",
              "        [-3.1470e-01],\n",
              "        [-4.1329e-01],\n",
              "        [ 3.9462e-01],\n",
              "        [ 1.1305e+00],\n",
              "        [ 8.2584e-01],\n",
              "        [ 9.4583e-01],\n",
              "        [-1.5447e-01],\n",
              "        [-1.6013e+00],\n",
              "        [-5.9471e-02],\n",
              "        [-9.9287e-01],\n",
              "        [ 1.1634e+00],\n",
              "        [ 1.6095e+00],\n",
              "        [-2.9417e-01],\n",
              "        [ 1.0819e+00],\n",
              "        [ 8.8662e-01],\n",
              "        [-8.6114e-01],\n",
              "        [-2.7265e-01],\n",
              "        [ 9.8042e-01],\n",
              "        [-1.7533e-01],\n",
              "        [-1.2277e-01],\n",
              "        [ 7.4141e-01],\n",
              "        [ 3.5395e-01],\n",
              "        [-5.3458e-01],\n",
              "        [ 6.4537e-01],\n",
              "        [-2.9891e+00],\n",
              "        [ 1.8371e-01],\n",
              "        [-4.7270e-01],\n",
              "        [-9.5882e-01],\n",
              "        [-1.5124e+00],\n",
              "        [ 1.5068e+00],\n",
              "        [-9.3805e-01],\n",
              "        [-6.3851e-01],\n",
              "        [ 2.1947e-01],\n",
              "        [-4.3924e-01],\n",
              "        [-1.3911e-01],\n",
              "        [-1.8692e-02],\n",
              "        [ 1.6561e+00],\n",
              "        [ 1.0661e+00],\n",
              "        [-1.8189e-01],\n",
              "        [-1.2380e+00],\n",
              "        [ 5.1422e-01],\n",
              "        [-1.5104e-01],\n",
              "        [ 1.3774e-01],\n",
              "        [ 1.2251e+00],\n",
              "        [-7.6426e-01],\n",
              "        [ 9.1838e-01],\n",
              "        [ 4.0577e-01],\n",
              "        [ 2.5105e-01],\n",
              "        [ 1.2815e-01],\n",
              "        [-1.9803e-01],\n",
              "        [-1.4780e+00],\n",
              "        [-5.9103e-01],\n",
              "        [ 8.3575e-01],\n",
              "        [-2.2925e-01],\n",
              "        [-1.2404e+00],\n",
              "        [ 2.4919e-01],\n",
              "        [-1.1416e+00],\n",
              "        [ 7.8214e-01],\n",
              "        [ 1.0817e-02],\n",
              "        [ 3.8163e-01],\n",
              "        [-1.6527e+00],\n",
              "        [-3.8140e-01],\n",
              "        [ 1.0699e-01],\n",
              "        [-1.0150e-01],\n",
              "        [ 8.3015e-02],\n",
              "        [ 7.1201e-01],\n",
              "        [-9.0059e-01],\n",
              "        [ 8.9069e-01],\n",
              "        [ 4.7655e-01],\n",
              "        [-8.3963e-01],\n",
              "        [ 3.3320e-01],\n",
              "        [-1.2526e+00],\n",
              "        [-5.7455e-01],\n",
              "        [-1.9059e+00],\n",
              "        [-9.6654e-01],\n",
              "        [ 3.6773e-01],\n",
              "        [-5.7858e-01],\n",
              "        [ 1.2373e+00],\n",
              "        [ 8.7134e-01],\n",
              "        [-5.2276e-01],\n",
              "        [ 1.2400e+00],\n",
              "        [-9.0577e-01],\n",
              "        [ 7.6803e-01],\n",
              "        [ 1.6222e+00],\n",
              "        [ 8.1580e-02],\n",
              "        [ 2.0282e-01],\n",
              "        [ 3.3024e-01],\n",
              "        [-9.5337e-01],\n",
              "        [ 1.5735e+00],\n",
              "        [ 1.8697e+00],\n",
              "        [-1.0639e+00],\n",
              "        [-2.2726e-01],\n",
              "        [ 2.5006e-01],\n",
              "        [ 1.1618e+00],\n",
              "        [-1.1422e-01],\n",
              "        [-5.6295e-02],\n",
              "        [ 8.4975e-01],\n",
              "        [-8.5991e-01],\n",
              "        [-6.1057e-01],\n",
              "        [ 1.0629e+00],\n",
              "        [ 1.2222e+00],\n",
              "        [ 7.7189e-01],\n",
              "        [-1.2797e+00],\n",
              "        [-1.5433e+00],\n",
              "        [-6.0202e-01],\n",
              "        [ 3.2140e-01],\n",
              "        [-6.0616e-02],\n",
              "        [-1.1704e+00],\n",
              "        [-2.7736e+00],\n",
              "        [-2.9824e-02],\n",
              "        [-9.1662e-01],\n",
              "        [ 4.7027e-01],\n",
              "        [ 1.8778e+00],\n",
              "        [ 5.2237e-01],\n",
              "        [ 5.1757e-02],\n",
              "        [ 4.2602e-01],\n",
              "        [ 9.4751e-01],\n",
              "        [ 4.3643e-01],\n",
              "        [-2.0531e-01],\n",
              "        [-1.4739e+00],\n",
              "        [ 5.0663e-01],\n",
              "        [ 2.7792e-01],\n",
              "        [ 1.3515e+00],\n",
              "        [-8.9496e-01],\n",
              "        [-1.5961e+00],\n",
              "        [ 6.7372e-01],\n",
              "        [-9.9707e-01],\n",
              "        [-3.4807e-01],\n",
              "        [ 2.1768e-01],\n",
              "        [ 1.1278e+00],\n",
              "        [-1.5005e+00],\n",
              "        [-2.4048e-01],\n",
              "        [-4.8549e-01],\n",
              "        [-6.6165e-02],\n",
              "        [-9.0293e-01],\n",
              "        [ 6.4402e-01],\n",
              "        [ 7.5918e-01],\n",
              "        [-2.0203e+00],\n",
              "        [-6.7395e-01],\n",
              "        [-9.1921e-01],\n",
              "        [ 1.2120e+00],\n",
              "        [-1.3463e+00],\n",
              "        [-4.8316e-01],\n",
              "        [ 1.7186e+00],\n",
              "        [-5.6843e-01],\n",
              "        [-2.9151e+00],\n",
              "        [ 1.0834e+00],\n",
              "        [ 7.7311e-02],\n",
              "        [ 1.2317e+00],\n",
              "        [ 2.9194e+00],\n",
              "        [ 1.9378e+00],\n",
              "        [-5.5362e-01],\n",
              "        [-1.3030e+00],\n",
              "        [ 1.0696e+00],\n",
              "        [-4.5618e-01],\n",
              "        [ 1.3635e+00],\n",
              "        [-2.4220e+00],\n",
              "        [-8.3080e-02],\n",
              "        [ 1.0349e-01],\n",
              "        [ 1.1661e-01],\n",
              "        [-2.5220e-02],\n",
              "        [ 3.7887e-01],\n",
              "        [ 2.4456e-01],\n",
              "        [-8.9158e-01],\n",
              "        [ 1.4344e+00],\n",
              "        [-1.9292e+00],\n",
              "        [-5.7138e-01],\n",
              "        [-6.6717e-01],\n",
              "        [-9.2035e-02],\n",
              "        [ 9.5487e-01],\n",
              "        [ 1.8483e-01],\n",
              "        [-1.1677e-01],\n",
              "        [-2.2911e-01],\n",
              "        [-3.4486e-01],\n",
              "        [-1.0765e+00],\n",
              "        [-5.4777e-01],\n",
              "        [-3.2893e-01],\n",
              "        [ 5.8413e-02],\n",
              "        [ 2.1100e+00],\n",
              "        [ 7.7261e-01],\n",
              "        [-3.4265e-01],\n",
              "        [ 1.2370e+00],\n",
              "        [-2.4977e-01],\n",
              "        [ 2.2397e-01],\n",
              "        [-6.8755e-01],\n",
              "        [-4.8984e-01],\n",
              "        [ 3.9969e-01],\n",
              "        [ 6.9820e-01],\n",
              "        [ 5.2110e-02],\n",
              "        [ 2.8821e-01],\n",
              "        [ 5.9505e-02],\n",
              "        [ 1.7286e+00],\n",
              "        [ 2.9208e-01],\n",
              "        [-6.9259e-01],\n",
              "        [-8.4428e-01],\n",
              "        [-3.2920e-01],\n",
              "        [-1.1403e-01],\n",
              "        [-8.4522e-01],\n",
              "        [ 3.0044e-01],\n",
              "        [ 1.6395e+00],\n",
              "        [-1.0744e+00],\n",
              "        [ 3.2122e-01],\n",
              "        [ 2.8923e-01],\n",
              "        [ 3.5197e-01],\n",
              "        [ 2.0988e+00],\n",
              "        [-5.2857e-01],\n",
              "        [-1.7715e+00],\n",
              "        [ 9.6894e-02],\n",
              "        [ 3.6735e-01],\n",
              "        [ 4.7319e-01],\n",
              "        [ 5.8768e-01],\n",
              "        [ 1.8398e-01],\n",
              "        [-8.4259e-01],\n",
              "        [-1.6972e+00],\n",
              "        [ 1.0872e+00],\n",
              "        [ 6.8014e-01],\n",
              "        [ 1.1617e+00],\n",
              "        [-1.7657e-01],\n",
              "        [ 5.2144e-01],\n",
              "        [-2.3571e+00],\n",
              "        [-8.3512e-01],\n",
              "        [-2.2620e+00],\n",
              "        [-1.2966e+00],\n",
              "        [ 3.2691e-01],\n",
              "        [ 6.0646e-01],\n",
              "        [-4.6069e-01],\n",
              "        [-8.8008e-01],\n",
              "        [-1.4766e+00],\n",
              "        [ 9.8293e-01],\n",
              "        [ 3.4096e-02],\n",
              "        [ 1.1689e+00],\n",
              "        [ 9.0257e-01],\n",
              "        [-1.7167e+00],\n",
              "        [ 4.6178e-02],\n",
              "        [ 9.3900e-02],\n",
              "        [-1.3564e+00],\n",
              "        [-1.0603e+00],\n",
              "        [ 1.0654e+00],\n",
              "        [ 5.4476e-01],\n",
              "        [ 1.5224e+00],\n",
              "        [ 2.3515e-02],\n",
              "        [ 2.8559e-01],\n",
              "        [ 2.0343e-02],\n",
              "        [ 9.2891e-01],\n",
              "        [-9.2389e-01],\n",
              "        [ 1.1474e+00],\n",
              "        [-7.0543e-01],\n",
              "        [ 1.1545e+00],\n",
              "        [-1.7463e+00],\n",
              "        [ 7.1034e-01],\n",
              "        [-1.0176e-01],\n",
              "        [-9.6634e-01],\n",
              "        [-1.4232e+00],\n",
              "        [-7.8465e-01],\n",
              "        [ 6.1071e-01],\n",
              "        [ 2.1427e-01],\n",
              "        [-1.7471e-01],\n",
              "        [-1.7561e+00],\n",
              "        [ 1.4259e+00],\n",
              "        [ 5.1272e-01],\n",
              "        [-4.0267e-01],\n",
              "        [ 1.9771e+00],\n",
              "        [ 2.6717e-02],\n",
              "        [-2.5021e-01],\n",
              "        [-9.1363e-02],\n",
              "        [-5.2833e-01],\n",
              "        [-4.6433e-01],\n",
              "        [-1.5669e-01],\n",
              "        [-1.5964e+00],\n",
              "        [-1.5322e+00],\n",
              "        [ 8.5622e-01],\n",
              "        [ 4.3222e-01],\n",
              "        [ 2.4113e-01],\n",
              "        [-5.4695e-02],\n",
              "        [ 4.7713e-02],\n",
              "        [-8.6376e-01],\n",
              "        [-1.1419e+00],\n",
              "        [-8.2924e-01],\n",
              "        [ 1.3149e+00],\n",
              "        [ 1.2471e+00],\n",
              "        [-2.5818e-01],\n",
              "        [-1.3405e+00],\n",
              "        [-5.5618e-01],\n",
              "        [ 1.1731e+00],\n",
              "        [ 6.8599e-01],\n",
              "        [ 8.6261e-01],\n",
              "        [-4.1024e-01],\n",
              "        [-7.5883e-01],\n",
              "        [ 1.6982e+00],\n",
              "        [ 7.4369e-01],\n",
              "        [-3.2767e-02],\n",
              "        [ 1.0600e+00],\n",
              "        [ 3.9094e-03],\n",
              "        [-6.9517e-01],\n",
              "        [-1.8830e+00],\n",
              "        [ 3.0457e-01],\n",
              "        [-7.0023e-01],\n",
              "        [ 1.7811e+00],\n",
              "        [-2.9368e-01],\n",
              "        [ 5.2430e-01],\n",
              "        [ 1.0186e+00],\n",
              "        [-1.5130e-01],\n",
              "        [ 1.1706e+00],\n",
              "        [ 1.6411e+00],\n",
              "        [ 4.2830e-01],\n",
              "        [-1.0704e+00],\n",
              "        [-6.1595e-01],\n",
              "        [-1.0195e+00],\n",
              "        [ 3.8482e-01],\n",
              "        [ 2.9435e-01],\n",
              "        [-1.7715e+00],\n",
              "        [ 4.3493e-01],\n",
              "        [ 6.3124e-02],\n",
              "        [-6.8945e-01],\n",
              "        [-2.8298e-01],\n",
              "        [ 6.6000e-01],\n",
              "        [-1.6193e-01],\n",
              "        [ 8.8608e-01],\n",
              "        [ 5.4842e-01],\n",
              "        [ 4.5765e-01],\n",
              "        [ 9.6769e-01],\n",
              "        [-6.6736e-01],\n",
              "        [ 1.6183e+00],\n",
              "        [-2.6440e-01],\n",
              "        [ 1.3541e+00],\n",
              "        [-7.0928e-02],\n",
              "        [-3.6971e-01],\n",
              "        [-2.4597e-01],\n",
              "        [ 3.2938e-01],\n",
              "        [ 6.9737e-01],\n",
              "        [ 8.3422e-01],\n",
              "        [-1.0987e+00],\n",
              "        [ 5.6748e-01],\n",
              "        [ 8.2838e-01],\n",
              "        [-3.8325e+00],\n",
              "        [ 1.1585e-01],\n",
              "        [ 1.9915e+00],\n",
              "        [ 1.0238e+00],\n",
              "        [ 2.1327e+00],\n",
              "        [ 2.3348e-01],\n",
              "        [ 1.2005e+00],\n",
              "        [-1.2669e+00],\n",
              "        [-9.4450e-01],\n",
              "        [-1.7938e-01],\n",
              "        [ 3.1205e-01],\n",
              "        [ 7.1738e-01],\n",
              "        [-2.3028e-01],\n",
              "        [ 7.1477e-01],\n",
              "        [ 1.4437e+00],\n",
              "        [ 1.9615e-01],\n",
              "        [-8.3326e-01],\n",
              "        [-9.5268e-01],\n",
              "        [-3.6367e-01],\n",
              "        [-1.2479e+00],\n",
              "        [-9.2614e-02],\n",
              "        [ 6.5336e-01],\n",
              "        [ 1.6370e-01],\n",
              "        [ 1.3456e+00],\n",
              "        [-3.6954e-01],\n",
              "        [-4.7142e-01],\n",
              "        [ 4.7792e-01],\n",
              "        [ 8.5095e-01],\n",
              "        [ 3.6884e-01],\n",
              "        [ 1.0622e+00],\n",
              "        [ 1.7639e+00],\n",
              "        [-4.8380e-02],\n",
              "        [ 9.1271e-01],\n",
              "        [-1.3906e+00],\n",
              "        [-7.0961e-01],\n",
              "        [ 9.3080e-01],\n",
              "        [-4.2432e-01],\n",
              "        [-4.8217e-01],\n",
              "        [ 4.7738e-01],\n",
              "        [-1.7900e-01],\n",
              "        [ 4.9374e-01],\n",
              "        [ 5.6121e-01],\n",
              "        [-1.7987e+00],\n",
              "        [-6.0785e-01],\n",
              "        [-5.8763e-01],\n",
              "        [-3.4518e-01],\n",
              "        [-7.2878e-01],\n",
              "        [-1.4958e+00],\n",
              "        [ 7.3510e-01],\n",
              "        [-2.6932e-01],\n",
              "        [ 4.5086e-01],\n",
              "        [ 4.0917e-02],\n",
              "        [-6.9333e-02],\n",
              "        [ 2.5858e-01],\n",
              "        [ 4.7755e-01],\n",
              "        [-1.4889e+00],\n",
              "        [-1.2930e+00],\n",
              "        [ 8.7957e-01],\n",
              "        [ 7.3064e-02],\n",
              "        [ 9.9674e-01],\n",
              "        [ 1.0238e+00],\n",
              "        [-1.2133e+00],\n",
              "        [ 9.7445e-01],\n",
              "        [ 4.5323e-01],\n",
              "        [-9.9276e-01],\n",
              "        [-2.5576e-01],\n",
              "        [-9.5857e-01],\n",
              "        [-5.7027e-01],\n",
              "        [ 1.9282e-01],\n",
              "        [ 3.8475e-01],\n",
              "        [-8.5958e-01],\n",
              "        [ 1.2815e+00],\n",
              "        [ 1.2761e-01],\n",
              "        [ 6.1011e-01],\n",
              "        [-1.2943e+00],\n",
              "        [ 6.0384e-01],\n",
              "        [ 1.1172e+00],\n",
              "        [ 4.1639e-01],\n",
              "        [ 6.7471e-01],\n",
              "        [ 2.2499e-01],\n",
              "        [-9.5563e-01],\n",
              "        [-7.7798e-01],\n",
              "        [ 6.9351e-01],\n",
              "        [-4.3586e-01],\n",
              "        [-9.8245e-01],\n",
              "        [-9.0629e-01],\n",
              "        [ 1.2596e+00],\n",
              "        [ 3.4627e-01],\n",
              "        [-2.0043e+00],\n",
              "        [ 5.5123e-03],\n",
              "        [ 4.6033e-01],\n",
              "        [ 1.1791e+00],\n",
              "        [-1.0106e+00],\n",
              "        [-6.2026e-01],\n",
              "        [-1.4549e+00],\n",
              "        [-5.8976e-01],\n",
              "        [-6.9602e-01],\n",
              "        [ 5.1550e-01],\n",
              "        [ 7.2376e-01],\n",
              "        [-1.8847e-01],\n",
              "        [-5.8210e-01],\n",
              "        [-4.3516e-01],\n",
              "        [-1.2878e+00],\n",
              "        [ 1.9290e+00],\n",
              "        [-1.7679e-01],\n",
              "        [ 6.3981e-01],\n",
              "        [ 6.9127e-01],\n",
              "        [ 5.1990e-01],\n",
              "        [-7.5461e-01],\n",
              "        [-3.3411e-02],\n",
              "        [-8.2765e-01],\n",
              "        [-3.5242e-01],\n",
              "        [-6.0023e-01],\n",
              "        [-5.7975e-02],\n",
              "        [ 2.9749e-01],\n",
              "        [ 1.6328e+00],\n",
              "        [-1.4954e+00],\n",
              "        [-2.9970e-01],\n",
              "        [-4.1446e-01],\n",
              "        [-7.8325e-01],\n",
              "        [-1.5083e+00],\n",
              "        [-1.3664e+00],\n",
              "        [ 9.6400e-01],\n",
              "        [ 4.0458e-02],\n",
              "        [ 2.4693e-01],\n",
              "        [ 1.1251e-01],\n",
              "        [-5.3494e-01],\n",
              "        [ 9.1711e-01],\n",
              "        [ 2.0659e+00],\n",
              "        [ 1.0178e+00],\n",
              "        [-1.9379e+00],\n",
              "        [-5.4771e-01],\n",
              "        [-1.8266e-01],\n",
              "        [-1.2373e+00],\n",
              "        [-1.6857e-01],\n",
              "        [ 6.8889e-01],\n",
              "        [ 1.0380e-01],\n",
              "        [-6.9890e-01],\n",
              "        [-5.0138e-01],\n",
              "        [-1.7143e-01],\n",
              "        [-1.5410e+00],\n",
              "        [-3.3021e-01],\n",
              "        [-7.3943e-01],\n",
              "        [-1.5103e+00],\n",
              "        [ 1.7838e-01],\n",
              "        [-1.7935e-01],\n",
              "        [-5.5837e-01],\n",
              "        [-8.8041e-01],\n",
              "        [-8.7913e-01],\n",
              "        [ 1.5491e+00],\n",
              "        [ 1.5372e-02],\n",
              "        [-2.7611e-02],\n",
              "        [-4.4803e-01],\n",
              "        [ 1.8764e+00],\n",
              "        [-8.9188e-01],\n",
              "        [ 4.3932e-01],\n",
              "        [-1.0310e+00],\n",
              "        [-1.4264e+00],\n",
              "        [ 7.1959e-01],\n",
              "        [ 5.9597e-01],\n",
              "        [-1.3461e+00],\n",
              "        [-5.3699e-02],\n",
              "        [-1.0823e+00],\n",
              "        [ 3.1819e-01],\n",
              "        [-2.2309e+00],\n",
              "        [-1.0310e+00],\n",
              "        [ 2.0589e-01],\n",
              "        [-8.3296e-01],\n",
              "        [ 9.6092e-01],\n",
              "        [-1.2231e+00],\n",
              "        [ 7.8281e-02],\n",
              "        [-1.5562e-01],\n",
              "        [ 4.0913e-01],\n",
              "        [ 4.9892e-01],\n",
              "        [-1.0029e+00],\n",
              "        [ 6.7861e-02],\n",
              "        [-5.3456e-01],\n",
              "        [-1.4052e+00],\n",
              "        [ 1.8912e+00],\n",
              "        [ 1.3595e+00],\n",
              "        [-8.4877e-01],\n",
              "        [-1.8412e+00],\n",
              "        [ 1.3573e+00],\n",
              "        [ 1.1483e+00],\n",
              "        [-8.5824e-01],\n",
              "        [-4.7482e-01],\n",
              "        [-9.5811e-01],\n",
              "        [-3.3481e-01],\n",
              "        [-1.7463e+00],\n",
              "        [ 2.9125e-01],\n",
              "        [-4.5711e-01],\n",
              "        [ 9.6024e-01],\n",
              "        [ 4.1718e-01],\n",
              "        [ 1.6658e+00],\n",
              "        [-1.8150e+00],\n",
              "        [-4.8884e-01],\n",
              "        [ 3.1906e-01],\n",
              "        [ 8.2072e-01],\n",
              "        [ 2.6855e-01],\n",
              "        [ 5.3491e-01],\n",
              "        [-1.9664e+00],\n",
              "        [ 3.4756e-01],\n",
              "        [-3.8398e-01],\n",
              "        [ 9.9964e-01],\n",
              "        [-4.1198e-01],\n",
              "        [ 1.7921e+00],\n",
              "        [-7.6727e-01],\n",
              "        [-1.3080e+00],\n",
              "        [-1.3159e+00],\n",
              "        [-1.2854e-01],\n",
              "        [ 1.3067e+00],\n",
              "        [ 1.9134e-01],\n",
              "        [ 1.3767e+00],\n",
              "        [ 6.8920e-01],\n",
              "        [ 4.3922e-01],\n",
              "        [-4.8140e-02],\n",
              "        [ 1.1222e+00],\n",
              "        [ 2.7943e+00],\n",
              "        [-8.4641e-02],\n",
              "        [-2.4345e-01],\n",
              "        [-1.4119e+00],\n",
              "        [-1.0504e+00],\n",
              "        [ 1.1106e+00],\n",
              "        [ 2.1369e-01],\n",
              "        [ 5.0677e-01],\n",
              "        [ 2.8286e-01],\n",
              "        [-1.1814e+00],\n",
              "        [-9.0017e-01],\n",
              "        [ 2.1022e+00],\n",
              "        [ 1.3313e-01],\n",
              "        [ 2.2425e-02],\n",
              "        [-2.7995e-01],\n",
              "        [-6.8478e-01],\n",
              "        [-7.9503e-01],\n",
              "        [-1.7334e+00],\n",
              "        [ 1.1859e+00],\n",
              "        [ 4.4658e-01],\n",
              "        [ 1.1301e+00],\n",
              "        [-3.3336e-01],\n",
              "        [ 8.9356e-01],\n",
              "        [-1.4336e+00],\n",
              "        [-8.7562e-01],\n",
              "        [ 9.3841e-03],\n",
              "        [ 6.3043e-01],\n",
              "        [ 8.6330e-01],\n",
              "        [ 1.1420e+00],\n",
              "        [ 3.1093e-01],\n",
              "        [-1.0642e-01],\n",
              "        [-7.9539e-01],\n",
              "        [-1.1213e+00],\n",
              "        [ 8.5798e-01],\n",
              "        [-1.6933e+00],\n",
              "        [ 2.8936e-01],\n",
              "        [ 1.2979e-01],\n",
              "        [ 8.0258e-01],\n",
              "        [ 2.0193e-01],\n",
              "        [ 3.8470e-01],\n",
              "        [ 1.7066e-01],\n",
              "        [ 1.3613e+00],\n",
              "        [-2.5743e-01],\n",
              "        [ 6.6737e-03],\n",
              "        [-5.4354e-01],\n",
              "        [-1.4135e+00],\n",
              "        [ 2.7878e+00],\n",
              "        [-1.0137e+00],\n",
              "        [ 1.0019e+00],\n",
              "        [ 8.6722e-01],\n",
              "        [ 2.4496e-01],\n",
              "        [ 1.3057e+00],\n",
              "        [-1.0610e+00],\n",
              "        [-4.0719e-02],\n",
              "        [-1.9681e+00],\n",
              "        [ 6.4619e-01],\n",
              "        [ 9.4744e-01],\n",
              "        [-9.6434e-01],\n",
              "        [-5.5447e-02],\n",
              "        [ 6.4874e-01],\n",
              "        [-1.5245e+00],\n",
              "        [-4.6295e-01],\n",
              "        [-1.6246e+00],\n",
              "        [ 1.4023e+00],\n",
              "        [ 3.8868e-01],\n",
              "        [ 7.2546e-01],\n",
              "        [-1.3895e+00],\n",
              "        [-8.5527e-01],\n",
              "        [-1.5335e+00],\n",
              "        [ 1.2889e-01],\n",
              "        [ 2.8911e-01],\n",
              "        [-7.3773e-01],\n",
              "        [ 8.8078e-01],\n",
              "        [-7.6626e-01],\n",
              "        [ 1.4586e+00],\n",
              "        [ 1.7724e+00],\n",
              "        [ 3.2966e-01],\n",
              "        [ 6.5873e-01],\n",
              "        [ 6.4284e-01],\n",
              "        [ 4.0178e-01],\n",
              "        [ 6.6231e-01],\n",
              "        [-8.1579e-01],\n",
              "        [ 1.7510e+00],\n",
              "        [-7.1193e-02],\n",
              "        [-3.1906e-01],\n",
              "        [ 9.8013e-01],\n",
              "        [ 1.1957e-01],\n",
              "        [-6.1245e-02],\n",
              "        [-9.4227e-01],\n",
              "        [ 1.4319e+00],\n",
              "        [ 1.3153e-01],\n",
              "        [-1.8222e-01],\n",
              "        [ 3.6604e-01],\n",
              "        [-6.7536e-01],\n",
              "        [-3.2092e-01],\n",
              "        [-1.2092e+00],\n",
              "        [ 7.7677e-02],\n",
              "        [ 1.7619e-01],\n",
              "        [ 5.7886e-01],\n",
              "        [ 1.5512e+00],\n",
              "        [ 8.4444e-02],\n",
              "        [-2.8735e-01],\n",
              "        [-6.6211e-01],\n",
              "        [-1.3968e-02],\n",
              "        [-2.7779e-01],\n",
              "        [-7.8568e-01],\n",
              "        [ 4.6062e-01],\n",
              "        [ 5.6622e-01],\n",
              "        [ 1.1542e+00],\n",
              "        [-2.3972e+00],\n",
              "        [ 3.8038e-01],\n",
              "        [-1.0243e+00],\n",
              "        [ 7.9945e-01],\n",
              "        [ 8.7001e-01],\n",
              "        [ 7.0074e-02],\n",
              "        [-3.3851e-01],\n",
              "        [-9.5478e-02],\n",
              "        [ 1.5840e-01],\n",
              "        [-8.3985e-01],\n",
              "        [ 1.6116e+00],\n",
              "        [-7.9801e-02],\n",
              "        [ 1.6326e+00],\n",
              "        [-2.2044e-01],\n",
              "        [-2.2251e-01],\n",
              "        [ 1.3148e-01],\n",
              "        [ 6.8301e-01],\n",
              "        [-1.3803e-01],\n",
              "        [ 1.4818e+00],\n",
              "        [ 1.6593e+00],\n",
              "        [ 4.0999e-01],\n",
              "        [-9.3318e-04],\n",
              "        [-1.0838e-01],\n",
              "        [ 4.7941e-01],\n",
              "        [-1.2923e+00],\n",
              "        [ 3.4748e-01],\n",
              "        [-6.3885e-03],\n",
              "        [-3.7650e-01],\n",
              "        [ 2.2679e+00],\n",
              "        [ 9.9913e-01],\n",
              "        [-2.9818e-01],\n",
              "        [-7.5647e-01],\n",
              "        [-2.0477e-01],\n",
              "        [ 1.4050e+00],\n",
              "        [-9.4348e-01],\n",
              "        [ 2.0284e+00],\n",
              "        [ 3.9312e-01],\n",
              "        [ 4.1331e-01],\n",
              "        [ 4.6390e-01],\n",
              "        [-2.9827e-02],\n",
              "        [ 1.2715e+00],\n",
              "        [ 1.0849e+00],\n",
              "        [-1.0124e+00],\n",
              "        [-1.4667e-01],\n",
              "        [-4.9659e-01],\n",
              "        [ 3.6382e-01],\n",
              "        [ 3.3970e-01],\n",
              "        [ 1.2731e+00],\n",
              "        [-1.5371e+00],\n",
              "        [ 1.0402e+00],\n",
              "        [-7.6420e-01],\n",
              "        [-4.4292e-01],\n",
              "        [-9.0904e-03],\n",
              "        [ 2.5302e-01],\n",
              "        [ 8.8957e-01],\n",
              "        [ 2.0152e+00],\n",
              "        [ 1.2288e-01],\n",
              "        [ 2.8316e-01],\n",
              "        [ 5.7904e-01],\n",
              "        [-1.9990e-01],\n",
              "        [-2.4691e+00],\n",
              "        [-1.6101e+00],\n",
              "        [ 1.7437e+00],\n",
              "        [-3.8771e-01],\n",
              "        [ 7.7233e-01],\n",
              "        [ 2.2672e-01],\n",
              "        [ 8.4670e-01],\n",
              "        [ 8.5032e-01],\n",
              "        [ 1.8044e+00],\n",
              "        [ 1.4647e+00],\n",
              "        [ 2.9134e-01],\n",
              "        [-1.1625e+00],\n",
              "        [-4.7836e-01],\n",
              "        [ 1.3870e+00],\n",
              "        [-5.1145e-02],\n",
              "        [-6.0138e-01],\n",
              "        [-1.1444e+00],\n",
              "        [-1.1234e+00],\n",
              "        [-7.9458e-01],\n",
              "        [-5.6948e-01],\n",
              "        [ 5.4942e-02],\n",
              "        [-7.6464e-01],\n",
              "        [-1.4184e+00],\n",
              "        [-8.9732e-01],\n",
              "        [-6.9965e-02],\n",
              "        [ 4.9443e-01],\n",
              "        [ 2.1871e+00],\n",
              "        [ 1.1618e+00],\n",
              "        [ 6.3469e-01],\n",
              "        [-4.3252e-01],\n",
              "        [-1.4113e+00],\n",
              "        [ 1.8677e+00],\n",
              "        [-9.8216e-01],\n",
              "        [-9.5810e-01],\n",
              "        [ 1.7746e+00],\n",
              "        [ 1.5162e+00],\n",
              "        [-1.0466e+00],\n",
              "        [ 1.3759e+00],\n",
              "        [-2.3220e-01],\n",
              "        [ 8.9476e-01],\n",
              "        [-1.1954e-01],\n",
              "        [ 7.8543e-01],\n",
              "        [-5.6178e-01],\n",
              "        [-4.7884e-01],\n",
              "        [-7.5233e-01],\n",
              "        [-4.7687e-01]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "HzNdZNs8slAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In neural networks the equation y =wx + b the y is the predicted value the w are weights and the b are the parameters\n",
        "#while the x are the input values\n",
        "#Both the weights are bias make up the parameters"
      ],
      "metadata": {
        "id": "cj6ylXlVs-k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction for one image with the following calculation:\n",
        "(train_x[0] * weights.T).sum() + bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZDkT586sbg8",
        "outputId": "b6e89848-da58-4399-fed0-9266d0c76a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.0042], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could use Python for loops to calculate the prediction for each image but that turns out to be very slow as python does not use GPU  and Python is very slow when it comes to loops in general. For convinience there is a mathematical operation that enables us to calculate the dot product of the weights and input/pixel values from images. This mathematical operation is called matrix multiplication which does this through multiplying the row of the weight matrix by the column of the input images."
      ],
      "metadata": {
        "id": "T_qLekNnt-07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate the matrix multiplication in python using the @ operator\n",
        "def linear1(xb):return xb@weights + bias"
      ],
      "metadata": {
        "id": "umfBCsi5tzWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function we take the input features which are the pixel values from our image and turn it into a 1 dimensional array which is called a vector and then do a batch matrix multiplication by the weights of the layer. The equation\n",
        "is batch@weights + bias"
      ],
      "metadata": {
        "id": "X0JULxry1MIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We calculate a \n",
        "prediction1 = linear1(train_x)"
      ],
      "metadata": {
        "id": "zBY4iI2LzHC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xcjpiB0zM3i",
        "outputId": "2792b810-a9f7-4d1d-ce2d-1ebce105ac17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.0042],\n",
              "        [ 0.9818],\n",
              "        [-2.9995],\n",
              "        ...,\n",
              "        [-9.1912],\n",
              "        [10.4335],\n",
              "        [-8.6594]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 was labeled as a  3 \n",
        "correct_three = (prediction1>0.0).float() == train_y "
      ],
      "metadata": {
        "id": "TAvrV_m0zOAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_three_accuracy = (prediction1>0.0).float().mean()"
      ],
      "metadata": {
        "id": "Wlo3-g6o2koU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_three_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAAYz26T3SH2",
        "outputId": "ca8ebac8-f78c-4993-cc43-8f98f5f77df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1620)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need gradients in order to improve our model using SGD stochastic gradient descent to get the gradients we need a loss functions. \n",
        "\n",
        "\n",
        "Gradients are a measure of how the loss function changes with small tweaks to the weights \n",
        "\n",
        "\n",
        "The purpose of a loss function is to measure the difference between the predicted values and the true values to see how much the function: y=wx+b changed when the input changed i.e the gradient in this case our weights"
      ],
      "metadata": {
        "id": "WbZmvPgN4R34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = tensor([1,0,1])"
      ],
      "metadata": {
        "id": "91NTC2AE3VdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tensor([0.2, 0.4, 0.9])"
      ],
      "metadata": {
        "id": "peKBNrOs-VEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loss(targets, predictions):\n",
        "  return torch.where(targets == 1, 1-predictions, predictions).mean()"
      ],
      "metadata": {
        "id": "rr_KQI2G-bvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = mnist_loss(targets,predictions)"
      ],
      "metadata": {
        "id": "By_FLRLG-qhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJwtxL1O-yS3",
        "outputId": "2d0d111a-fa4a-41db-c167-c679a6eb6705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4333)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scalar is one number a vector is a one dimensional matrix that has only one row and one column a matrix is a two dimensional array of numbers that contains n rows and n columns. In pytorch a lower number is associated with a better loss since we need only one value for from our loss function and we obtain this through adding the mean() method."
      ],
      "metadata": {
        "id": "rHH71iga_RBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sigmoid function is a mathematical operation or a function that takes in an input value and outputs a value in between a zero and a one"
      ],
      "metadata": {
        "id": "1dPQV3MBwu-b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM3tpN_IwfbH"
      },
      "outputs": [],
      "source": [
        "#This is how we define a sigmoid function:\n",
        "def sigmoid(x): return (1/1+torch.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "mK4y--q_xRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we plot the function on a graph to visualize it\n",
        "\n",
        "plot_function(torch.sigmoid, title=\"Sigmoid\", min =-10, max =10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "huNGmupMxva9",
        "outputId": "53a3e4c7-2417-439b-9466-99d3a427f979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEMCAYAAAA/Jfb8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcdX3/8ddn9p7dbK6bhNzJFQgQApFbDKAgIEi5pFoVubSlqVDF2orl159URFsLir9Hq1RMKyD8ELFCFAiGQAUhBIGEkMvmDjE3spvNbe+3mfn0j5nFYZzNTrKze2Zm38/HYx4z55zvnPnku2feOfOdM+eYuyMiIvklFHQBIiKSeQp3EZE8pHAXEclDCncRkTykcBcRyUMKdxGRPKRwl7xjZnea2bag6+hiZg+Z2Qs9tLnRzML9VZPkP4W75BQzKzOzb5rZVjNrNbODZvammd2a0Oy7wNlB1ZjCl4BPBl2EDCyFQRcgcpR+CHyEWGCuASqBOcDErgbu3gQ0BVJdCu5eH3QNMvBoz11yzVXAd9z9l+6+3d3XuPtD7n5XV4NUwzJm9rdmttvMWszsOTO7zszczMbHl99oZmEz+4iZrYt/KnjJzMaa2XlmttrMms3sBTMbl7TuG8xsg5l1xF/jW2ZWmLD8A8MyZhaKf/rYZ2ZNZvY4MKyvOkwGJoW75Jq9wKVmNjzdJ5jZNcSGar4DzAYeA+5O0TQEfB24CZgHjAMeB+4Cbo7PGw98L2HdlwMPAI8AJwN/D/xNfD3d+SLwd8BtwOnAqh7aixw9d9dNt5y5EQvYHUAEWAssIrY3bwlt7gS2JUy/CjyStJ5/BRwYH5++MT59WkKb2+LzzkiY92Vgf8L0K8DPk9b9JaAVKI5PPwS8kLB8N/DPSc/5BRAOun91y5+b9twlp7j7q8BUYD7wE2A0sWB8ysysm6edBPwuad5rqVYPrEuYronfr02aN8LMCuLTs4CXk9bzW6A0XucHmFklsU8EK5IWLe+mdpFjonCXnOPuYXdf4e73uvuVxPa6PwGcd6SnpbHqqLtHkp/j7p0p1tPdfyQiWUHhLvlgY/x+VDfLNwDnJM3L1KGS1fzxfyrnExuWeSe5sbs3AHuAc5MWzctQPSKADoWUHGNmvyX2hehKoA6YBvwLcBh4sZun3Qs8bmZvAL8mFqzXx5f19oIG3waeNrPbgSeB04iN+d/r7h1HqOebZraJ2HDRnwAX9bIOkQ/Qnrvkml8D1wLPApuBB4GtwDx335/qCe7+JPBV4HZiY+rXAt+IL27rTTHu/izwF8ANwHrg/wH/kbD+VP4N+Pd427eJfaq46wjtRY6auetKTDLwmNk/Abe6+8igaxHpCxqWkbxnZkXEjj9/Fmgm9gvX24D7gqxLpC9pz13yXvzXos8AZwCDge3Aw8R+6aqTdUleUriLiOQhfaEqIpKHsmLMfeTIkT558uSgyxARySmrVq3a7+5VqZZlRbhPnjyZlStXBl2GiEhOMbMd3S3TsIyISB5SuIuI5CGFu4hIHlK4i4jkIYW7iEgeSivczewLZrbSzNrN7KEe2n7ZzGrMrMHMHjCzkoxUKiIiaUt3z/094FvErhXZLTO7hNiZ9y4EJgFTOPLZ8UREpA+kdZx7/JSpmNlcYhcI7s4NwI/dvTre/pvAo8QCX0SkW+FIlPZwlI5w7L4z8of7cMTpiEQJR6JEok446h+4j3ryPUTj01GHaPy6olHn/fto/NQr7uB4/P4P013LusSuTRp/nLDMEy4J0N3ZXD4wO6nR3MnDOW9Gyt8h9Uqmf8Q0C/hVwvQaYLSZjXD3A4kNzWwhsBBg4sSJGS5DRPpTNOocaO5gf1M7B5s7ONDcweGWDupbOqlv7aSxLUxje+y+uT1MS0fk/Vt7Z4TWzgjh6MA5z1Xi1X4/f/7UnAj3CqA+Ybrr8WDgA+Hu7ouIXbmeuXPnDpy/qkgOcndqGtp4t66Zd/c3s/tgC7sPt7LnUCu1DW3UNbZ3G85lRQVUlhUyuLSIipJCyksKGFlRQnlJIaVFBZQVFVBaFKK0qICSwhAlhSGKCkMUF4Qojt8XFYQoLDAKQ7H7ogIjZLHpUAgKQkaBGaH4fUHIMINQwmPDCMXnmYF13RN/DO+3Swzfrnl/eNw13xIeJ7bPjsvrZjrcm4DKhOmux40Zfh0R6SPhSJRNNY2s3nWYjXsb2Li3gc01jbR0/OHa4cUFIcYOLWXcsDLmTRvJ6MoSRg0upWpwCcPLixlRXszQQcUMKSuiuFAH5QUh0+FeDcwGfh6fng3UJg/JiEj2CEeirNldz6vb9rPinf2s2VVPa2csyIeUFXHCmMF8au4Epo6qYOrIciaPLGdMZSmhUHbsoUpqaYV7/GIHhUABUGBmpUA4xYUOHgYeMrNHiR1h8zXgocyVKyKZ0NYZ4aXNdSxdv5f/2bSPxrYwZjBrbCV/9qEJnD5pGHMmDGX8sLKsGWaQo5PunvvXgK8nTH8O+IaZPQBsAE5y953uvtTM7iF2Ffoy4Imk54lIQNydt3Ye4rE3dvHsur20dEQYNqiIS2eN4YKZozhn6giGlxcHXaZkSFZciWnu3LmuU/6K9I32cIQn39rDA8u3s3VfE+XFBVwxeyxXzB7LWccPp7BAY+K5ysxWufvcVMuy4nzuIpJ5LR1hfvr6Tv7zlXepbWjn5HGV3L3gFD5x6ljKS/TWz3f6C4vkmWjU+dWaPdz9683UNLRxzpQR3PvJ05g3bYTGzwcQhbtIHlm3u547frWet3cd5tTxQ/j3z8zhzOOHB12WBEDhLpIHOiNRfvCbbfzgxW0MLy/mu5+czTVzxulwxQFM4S6S47bta+LLj7/Nuj31XD1nHHdeMYshg4qCLksCpnAXyWEvbKjlbx9/m+LCEPd/7nQuPfm4oEuSLKFwF8lB7s5/vPQO3122mZPHDmHR9Wdw3JCyoMuSLKJwF8kx4UiUrz6xliff2sOfzB7LPX96KqVFBUGXJVlG4S6SQzojUf72Z2+zZN1evnzRDG69cJoOb5SUFO4iOaI9HOELP13N8xtq+drlJ3LT/ClBlyRZTOEukgPCkSh/8+hbvLBxH3ddOYvrz5kcdEmS5RTuIlnO3fn6U9W8sHEf37xyFtcp2CUNOmOQSJa7/7fv8ujrO7n5gqkKdkmbwl0kiz215j3uXrqJK2aP5baLZwZdjuQQhbtIltpc08ht/72GMycP57ufPFWnEpCjonAXyUItHWH+5qdvMbi0iPuuPZ2SQh3HLkdHX6iKZKE7flnNO3VN/P+/PIuqwSVBlyM5SHvuIlnmF6t288Rbu/niR6Yxb9rIoMuRHKVwF8kiuw+18E+/Ws+Zxw/n1gunB12O5DCFu0iWcHe+9sv1AHzvU7N1bVPpFW09IlniqTXv8dLmOr5y8UzGDxsUdDmS4xTuIlngYHMH33h6A7MnDOWGcycHXY7kAYW7SBb41pINNLR2cveCUyjQ8eySAQp3kYCt2nGQJ9/aw+fPn8oJYyqDLkfyhMJdJEDuzreWbGTU4BJu+cjUoMuRPKJwFwnQknV7Wb3zMF+5eCaDivWbQskchbtIQNrDEe5euokTxgxmwRnjgy5H8ozCXSQgD6/Ywa6Drfzfy0/Ul6iScQp3kQDUt3Ty/d9s5fwZVcyfXhV0OZKHFO4iAXhwxXYa2sJ89VKdo136RlrhbmbDzWyxmTWb2Q4z+2w37UrM7H4zqzWzg2b2tJmNy2zJIrmtsa2TB5Zv52MnjWbW2CFBlyN5Kt099/uADmA0cC3wQzOblaLdl4BzgFOBscAh4PsZqFMkbzz82g4a2sLc+lGdGEz6To/hbmblwALgDndvcvflwFPAdSmaHw885+617t4GPA6k+k9AZEBqbg/zX6+8ywUzqzhlvPbape+ks+c+Awi7+5aEeWtIHdo/BuaZ2VgzG0RsL//XqVZqZgvNbKWZrayrqzvaukVy0qOv7+BQSydf1F679LF0wr0CaEiaVw8MTtF2K7AL2BN/zonAXalW6u6L3H2uu8+tqtLRApL/2jojLHp5Ox+eNpIzJg0LuhzJc+mEexOQfMKLSqAxRdv7gBJgBFAOPEk3e+4iA83i1XvY39Su0wxIv0gn3LcAhWaW+DlyNlCdou1pwEPuftDd24l9mXqmmelaYTKguTsPvrqdk46r5JwpI4IuRwaAHsPd3ZuJ7YHfZWblZjYPuBJ4JEXzN4HrzWyImRUBtwDvufv+TBYtkmte3XaALbVN/Pm8yZjp16jS99I9FPIWoAzYBzwG3Ozu1WY238yaEtp9BWgjNvZeB1wGXJ3BekVy0gOvbmdkRTFXzB4bdCkyQKR1Gjp3PwhclWL+K8S+cO2aPkDsCBkRidu+v5nfbNrHrRdOp7SoIOhyZIDQ6QdE+thDr26nqMD43NkTgy5FBhCFu0gfamjr5BerdnPFqWMZNbg06HJkAFG4i/ShX67eQ3NHhBvnTQ66FBlgFO4ifcTdeeyNXcwaW8mp44cGXY4MMAp3kT6ydnc9G/c28OkzNdYu/U/hLtJHfvbmTsqKCrjyNB3+KP1P4S7SB5rbwzz19ntcfupxVJYWBV2ODEAKd5E+8Mza92juiPCZMycEXYoMUAp3kT7w2Bu7mDaqgtMn6uyPEgyFu0iGba5p5O1dh/n0hyboPDISGIW7SIY98dZuCkPGNaePD7oUGcAU7iIZFIk6v3p7DxfMHMXw8uKgy5EBTOEukkGvvXOA2oZ2rp4zLuhSZIBTuItk0OLVexhcUsiFJ44KuhQZ4BTuIhnS2hFh6fq9XHbKcTq1rwRO4S6SIcs21NDcEeEqDclIFlC4i2TI4tV7GDuklLOOHx50KSIKd5FMqGts55Wt+7lyzjhCIR3bLsFTuItkwJK17xGJOledpiEZyQ4Kd5EMeGbtXmaOHszMMYODLkUEULiL9Nre+lZW7jjEJ049LuhSRN6ncBfppWfX1QBwmcJdsojCXaSXlqx9jxOPq2RqVUXQpYi8T+Eu0gt7Drfy1s7DGpKRrKNwF+mFZ9fuBVC4S9ZRuIv0wjPr9nLKuCFMGlEedCkiH6BwFzlGuw62sGbXYS7XXrtkIYW7yDFasi42JHP5KQp3yT4Kd5FjtHR9DaeMG8KE4YOCLkXkj6QV7mY23MwWm1mzme0ws88eoe3pZvaymTWZWa2ZfSlz5Ypkh731rby96zCXnjwm6FJEUipMs919QAcwGjgNWGJma9y9OrGRmY0ElgJfBn4BFAO6kKTknWXVtQAKd8laPe65m1k5sAC4w92b3H058BRwXYrmfwc85+6Punu7uze6+8bMliwSvKXra5g+qkI/XJKslc6wzAwg7O5bEuatAWalaHs2cNDMVpjZPjN72swmplqpmS00s5VmtrKuru7oKxcJyMHmDl7ffkB77ZLV0gn3CqAhaV49kOr0d+OBG4AvAROB7cBjqVbq7ovcfa67z62qqkq/YpGAPb+hhqjDJbMU7pK90hlzbwIqk+ZVAo0p2rYCi939TQAz+waw38yGuHt9ryoVyRJL19cwYXgZs8Ymvy1Eskc6e+5bgEIzm54wbzZQnaLtWsATpj1FG5Gc1dDWyavbDnDprDGY6YpLkr16DHd3bwaeBO4ys3IzmwdcCTySovmDwNVmdpqZFQF3AMu11y754sVN++iIRDXeLlkv3R8x3QKUAfuIjaHf7O7VZjbfzJq6Grn7b4B/BJbE204Duj0mXiTXLKuupWpwCXMmDAu6FJEjSus4d3c/CFyVYv4rxL5wTZz3Q+CHGalOJIu0hyO8tHmfLoItOUGnHxBJ04p3DtDcEeFjJ40OuhSRHincRdK0rLqW8uICzp06IuhSRHqkcBdJQzTqvLCxlgtmjqKksCDockR6pHAXScPbuw9T19jOxbM0JCO5QeEukoZl1bUUhowLZo4KuhSRtCjcRdKwbEMNZ08ZwZCyoqBLEUmLwl2kB9v2NfFuXbOGZCSnKNxFevD8hti52y86UeEuuUPhLtKDZRtil9MbO7Qs6FJE0qZwFzmCfY1tvL3rsH64JDlH4S5yBL/ZuA93FO6ScxTuIkfw/IZaxg8r44Qxqa5NI5K9FO4i3WjpCLN8234+dtJonbtdco7CXaQbL2/ZT3s4qiEZyUkKd5FuPL+hliFlRZw5eXjQpYgcNYW7SArhSJTfbKrloyeMorBAbxPJPdpqRVJYteMQh1o6NSQjOUvhLpLC8xtqKS4Icd6MqqBLETkmCneRJO7O8xtrOXfaCCpK0roSpUjWUbiLJNm6r4kdB1q4+KQxQZcicswU7iJJllXXAHDRiTp3u+QuhbtIkmUbapkzcSijKkuDLkXkmCncRRLsrW9l7e56DclIzlO4iyR4IX7udh0CKblO4S6SYNmGWqZUlTNtVEXQpYj0isJdJK6+tZPX3jmgIRnJCwp3kbiXNu8jHHUNyUheULiLxC3bUMvIihLmTBgadCkivaZwFwHaOiO8uGkfHztpNKGQzt0uuU/hLgIs37qflo4IHz9Z4+2SH9IKdzMbbmaLzazZzHaY2Wd7aF9sZhvNbHdmyhTpW0ura6gsLeTsKSOCLkUkI9I9K9J9QAcwGjgNWGJma9y9upv2twF1gC48KVmvMxLlhY21XHTiaIoL9WFW8kOPW7KZlQMLgDvcvcndlwNPAdd10/544HPAtzNZqEhfeWP7QQ63dHKJhmQkj6SzmzIDCLv7loR5a4BZ3bT/PvCPQOuRVmpmC81spZmtrKurS6tYkb6wdH0NZUUFnK9zt0seSSfcK4CGpHn1pBhyMbOrgQJ3X9zTSt19kbvPdfe5VVV6U0kwolHnueoaPnJCFaVFBUGXI5Ix6Yy5NwGVSfMqgcbEGfHhm3uAyzJTmkjfW73rEPsa27lkloZkJL+kE+5bgEIzm+7uW+PzZgPJX6ZOByYDr5gZQDEwxMxqgLPd/fcZqVgkg5aur6G4IMRHT9C52yW/9Bju7t5sZk8Cd5nZTcSOlrkSODep6XpgQsL0ucAPgNOJHTkjklXcnV+vr2HetBEMLi0KuhyRjEr3uK9bgDJgH/AYcLO7V5vZfDNrAnD3sLvXdN2Ag0A0Ph3pk+pFemHt7np2H2rlslOOC7oUkYxL6zh3dz8IXJVi/ivEvnBN9ZyXgPG9KU6kLz2z9j2KCoyLNd4ueUi/2JAByd1ZsnYv502vYkiZhmQk/yjcZUBavesw79W3cfmpGpKR/KRwlwHpmTV7KS4M6dztkrcU7jLgRKPOs+v2cv6MKh0lI3lL4S4Dzls7D1HT0MYnNCQjeUzhLgPOM2v3UlIY4sITNSQj+UvhLgNKJOosWbeXC2ZWUVGS7hmvRXKPwl0GlBXv7KeusZ2rThsXdCkifUrhLgPK4rf2MLi0kI/oXDKS5xTuMmC0dIRZWl3DJ049Tqf3lbyncJcBY1l1LS0dEQ3JyICgcJcBY/HqPYwbWsaHJg8PuhSRPqdwlwFhX2Mbr2yt46o5YwmFLOhyRPqcwl0GhKfX7CXqcPUcDcnIwKBwlwFh8erdnDJuCNNG/dGlf0XyksJd8t6G9xpYv6dBe+0yoCjcJe89/uZOigtCCncZUBTuktfaOiMsXr2HS08ew7Dy4qDLEek3CnfJa8+u20tDW5hPnzmh58YieUThLnntZ2/sYvKIQZwzZUTQpYj0K4W75K1t+5p44/cH+bMPTcRMx7bLwKJwl7z185W7KAwZC87QF6ky8CjcJS+1hyM8sWo3F544ilGDS4MuR6TfKdwlLz2zZi8Hmju49qxJQZciEgiFu+Qdd+fBFduZNqqC+dNHBl2OSCAU7pJ3Vu44xPo9Dfz5vMn6IlUGLIW75J0Hlm9nSFkR18wZH3QpIoFRuEte2X2oheeqa/jMmRMpK9bVlmTgUrhLXnnktR2YGdefoy9SZWBLK9zNbLiZLTazZjPbYWaf7abdbWa23swazWy7md2W2XJFutfcHuaxN3Zy6cljGDu0LOhyRAJVmGa7+4AOYDRwGrDEzNa4e3VSOwOuB9YCU4FlZrbL3X+WqYJFuvPo6ztoaAtz04ePD7oUkcD1uOduZuXAAuAOd29y9+XAU8B1yW3d/R53f8vdw+6+GfgVMC/TRYska+2IsOjl7cyfPpI5E4cFXY5I4NIZlpkBhN19S8K8NcCsIz3JYsegzQeS9+67li80s5VmtrKuri7dekVSeuyNnexvaueLH50edCkiWSGdcK8AGpLm1QM9Xa/szvj6H0y10N0Xuftcd59bVVWVRhkiqbV1RvjRy+9w1vHDOfP44UGXI5IV0gn3JqAyaV4l0NjdE8zsC8TG3i939/ZjL0+kZ/+9aje1De186ULttYt0SSfctwCFZpb4zplN98MtfwHcDlzo7rt7X6JI9zrCUe5/6R3OmDSMc6bqnO0iXXoMd3dvBp4E7jKzcjObB1wJPJLc1syuBf4F+Ji7v5vpYkWS/fT1Hew53MqtF07XqQZEEqT7I6ZbgDJgH/AYcLO7V5vZfDNrSmj3LWAE8KaZNcVv92e2ZJGY+tZO/u1/tjJv2gjO0wnCRD4grePc3f0gcFWK+a8Q+8K1a1oHGEu/+Y8Xt3G4tZN/vOxE7bWLJNHpByQn7TrYwoOv/p4Fp49n1tghQZcjknUU7pKT7nluM6EQfOXimUGXIpKVFO6Sc1btOMjTa95j4fwpjBmiS+iJpKJwl5zSEY5y+xPrGDuklIXnTw26HJGsle6Jw0Sywg9feoet+5p44Ma5VJRo8xXpjvbcJWdsrW3kBy9u5U9mj+WjJ4wOuhyRrKZwl5wQjTq3P7mO8pJC/umKk4IuRyTrKdwlJ/x4+XZW7TjEHZefxMiKkqDLEcl6CnfJeqt3HuLupZu4+KTRXHP6uKDLEckJCnfJavUtnXzhp6sZM6SU7/zpbP0SVSRNOtxAspa789Un1lDb0MZ/f/4chgwqCrokkZyhPXfJWv/5yrs8V13LP1x6gi6dJ3KUFO6SlZas3cu/PLuJy085jpvm63x0IkdL4S5ZZ+XvD/Lln7/N3EnDuPdTGmcXORYKd8kq79Y18VcPr2Tc0DL+8/q5lBYVBF2SSE5SuEvW2LaviU8v+h0hMx768w8xrLw46JJEcpaOlpGssLmmkWv/63eA8djCs5k0ojzokkRymvbcJXDrdtfz6UWvURAyHv/rs5kxenDQJYnkPIW7BOqZte/xyR+tYFBxIY8vPIepVRU9P0lEeqRhGQlENOp87/kt/ODFbZwxaRj3f+4MqgbrnDEimaJwl35X29DGV3+xlt9uqePP5k7grqtmUVKoo2JEMknhLv3qqTXvcccv19MejvDNq07mc2dN1HHsIn1A4S79YueBFv752Q08V13LaROG8r1PzWaKxtdF+ozCXfpUY1sn9734Dg8s305ByLjtkpn89XlTKCzQd/kifUnhLn3icEsHP1mxgwdXbOdwSyfXnD6Or15yAmOGlAZdmsiAoHCXjNq2r4nH3tjJz97YSXNHhItOHMUXPzqd2ROGBl2ayICicJdeq2/pZNmGGn6+chdv/v4QhSHjslOO4+YLpnLicZVBlycyICnc5ZjsOtjCy1vreK66lhXb9hOOOsePLOf2j5/AgtPH65h1kYAp3KVH7s7vD7Tw1o5DrNp5iFe37WfHgRYAJg4fxF/OP56Pn3wcs8cP0WGNIllC4S4fcKi5g3f3N/NOXROb9jayqaaBjXsbONTSCUBFSSFnHT+cG8+dzIenjWTaqAoFukgWSivczWw48GPgYmA/8H/c/acp2hnwr8BN8Vn/Bdzu7p6ZcuVYRaNOfWsnB5o7ONDUTm1jO/sa2qipb2PP4VZ2H2pl16EWDsdDHKC0KMTMMZVcMmsMsycM5fSJw5g2qoKCkMJcJNulu+d+H9ABjAZOA5aY2Rp3r05qtxC4CpgNOPA8sB24PzPl5gd3JxJ1Iu5EoxCORolGoTMaJRJ1OiNRwpHYfUckSmfE6QhHY7dIhPbOKG3hCG2dUVo7IrR2RmjpCNPcHrtvag/T2BamoS1MQ2snh1s6aGgLE4n+8f+xpUUhxg0tY9ywQZwyfghTRpZzfPw2aUS5glwkR/UY7mZWDiwATnb3JmC5mT0FXAfcntT8BuBed98df+69wF/RR+H+2y11fPOZDe9Pd/cBwbuZ6Hro7gmPoWuqa3WJq+1q29Uu6l3Lux7H7qPuePw+2jUvHuh98TmmIGQMKipgUEkBg0uLGFxayJCyIiYOH8SQskKGlhUzvLyYERXFjCgvYXRlCaMGl1JZVqhhFZE8lM6e+wwg7O5bEuatAc5P0XZWfFliu1mpVmpmC4nt6TNx4sS0ik1WUVLIzORzf3eTU4mzE8PM3p+X+Nj+0N667gyzP8yKtTdCofhSg5BBKP7cUMjef1wQMsyMkMUeh8woCFnCYygMhSgsiM0rij8uLAhRXBCiuNAoLiiguDBESWGI4sIQZUUFlBYVUFoUorSogJLCkEJaRN6XTrhXAA1J8+qBVFdUqIgvS2xXYWaWPO7u7ouARQBz5849pn3ZMyYN44xJw47lqSIieS2dE3w0Acm/RKkEGtNoWwk06QtVEZH+lU64bwEKzWx6wrzZQPKXqcTnzU6jnYiI9KEew93dm4EngbvMrNzM5gFXAo+kaP4w8HdmNs7MxgJ/DzyUwXpFRCQN6Z539RagDNgHPAbc7O7VZjbfzJoS2v0IeBpYB6wHlsTniYhIP0rrOHd3P0js+PXk+a8Q+xK1a9qBr8ZvIiISEF0xQUQkDyncRUTykMJdRCQPWTYcgm5mdcCOY3z6SGInM8s22VoXZG9tquvoqK6jk491TXL3qlQLsiLce8PMVrr73KDrSJatdUH21qa6jo7qOjoDrS4Ny4iI5CGFu4hIHsqHcF8UdAHdyNa6IHtrU11HR3UdnQFVV86PuYuIyB/Lhz13ERFJonAXEclDCncRkTyU9eFuZl8ws5Vm1m5mD6VYfqGZbTKzFjN70cwmHWFdk+NtWuLPuSiDdTYl3SJm9v1u2t4YX57Y/oJM1ZL0Wi+ZWVvC62w+Qlszs7vN7ED8drf1wbX7zKzEzH5sZjvMrNHM3jazjx+hfZ/2l5kNN7PFZtYcr+mz3bTrl/6Jv1bafdSf21P89dLapvq5v7Lm/XekzNnDrj8AAAQtSURBVOrXvHL3rL4B1xA7I+UPgYeSlo0kdim/TwKlwHeA3x1hXa8B3yN2+uIFwGGgqg9qriB2Varzull+I7C8n/rvJeCmNNv+NbAZGA+MAzYAn++DmsqBO4HJxHYwPkHsyl6Tg+gvYqexfjz+d/twfJuaFVT/HG0f9ef2dDTbVH/2V9LrBvr+6y6z+juv+mVjyFCHfStFuC8EViRMlwOtwAkpnj8DaAcGJ8x7pY/C6wbgXeJHI/X3xpX0WkcT7iuAhQnTf3mkjS/Dda4FFvR3f8W3mQ5gRsK8R4B/zab+OVIfZXG4B9Jf2fL+S86s/s6rrB+W6cEsYE3XhMeuGvVOfH6qtu+6e+K1X9d007a3bgAe9vhfpBtzzGy/mW0xszvMLK1z6x+jb8df69UePn5+oD/pu/75ADMbTWxjPtIlGfuqv2YAYXffkjCvu393IP0DafVRf25PkN42FVR/Zdv7r0u/5lWuh3sFsY85ieqBwb1se8ziY2jnAz85QrOXgZOBUcQ+bn0GuC2TdST4B2AKsY/Fi4CnzWxqN22T+6geqOircVIAMysCHgV+4u6bumnWl/1VATQkzUt3G+rz/oG0+qg/tydIf5sKYnvKtvdfon7Nq0DDPf7FjHdzW57GKpqAyqR5lcTGJnvTtjd1XkfsI9/27tbn7u+6+3Z3j7r7OuAu4E97quNY6nL319290d3b3f0nwKvAZd2sMrmPKoGmHvaAjqmueLsQsSGQDuAL3a0vU/3Vjd5sQ8fUP0cjnT7q4/5J9XrpblP93l/04/vvGPRLXnUJNNzd/QJ3t25uH05jFdXA7K4JMysHppL6o2s1MMXMEv/nm91N297UeT1H3mtI+RLAUe/NHGP/Hem1PtCfpNk/x1JXfO/tx8BoYuPInUfzEkf4NxytLUChmU1PmNfdvzsj/ZOuXvRRJvunN6/Xr/0V12/vv2PQL3n1vr7+UqG3N2LXeS0Fvk1sD6YUKIwvqyL2UWVBfP7dHPnb598B3423vZoMHy0DnAs0k/AlSDftPg6Mjj8+gdjFxL/eB303FLikq8+Aa+P1zeim/eeBjcQ+bo+Nb0h9dTTI/fG/R0Uabfu0v4CfETtiphyYR/dHy/Rb/xxNH/XX9nS021QA/ZUV77/uMqu/86pPOjnDf7A7if3Pmni7M2H5RcAmYt86v0TCoWLxN8f9CdOT421aiR2idVGGa/0R8EiK+ROJfcyaGJ/+LlAb3xDfJfaxsKgP+q4KeJPYR7nD8Y3lYwnL5xP7mNw1bcA9wMH47R66OeKgl3VNiv8d2+L90nW7Noj+AoYDv4yvfyfw2SD7p6c+Cmp76mmbCrK/4q+XFe8/jpBZ9GNe6cRhIiJ5KNePlhERkRQU7iIieUjhLiKShxTuIiJ5SOEuIpKHFO4iInlI4S4ikocU7iIieeh/AXCPhL+z2a8SAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We redefine our loss function to apply sigmoid function to our predicted values,this ensures that our loss function takes in values that\n",
        "#are in between zero and one \n",
        "def mnist_loss(targets, predictions):\n",
        "  predictions = predictions.sigmoid()\n",
        "  return (torch.where(targets == 1, 1 - predictions, predictions)).mean()"
      ],
      "metadata": {
        "id": "ee9oXfWDy-Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We defined a loss function to ensure that gradient descent/ automated learning can be smoothly applied to our model.\n",
        "The loss enables us to see how far our machine learning model is from the desired goal. You can think of the loss a perfomance evaluation technique during training. The metric is used to drive human understanding while the loss function is used to enable our model to learn effectively through application of gradient descent and so on."
      ],
      "metadata": {
        "id": "nNRJglWc1Ikm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step after obtaining the loss is to change and update the weights based on the loss, this is known as taking an optimization step:(i.e , taking an optimization step is changing and updating the weights based on the loss). To take an optimization step we have to calculate the loss of a single or more data items. Calculating the loss for the whole dataset would relatively take a long time and calculating the loss for a single data item wouldn't give much and precise information thus will lead to unstable gradients. The walk around for this is to calculate the average loss for a few data items at a time,this is called a mini-batch. The batch size is the number of data items in a mini batch.\n",
        "\n"
      ],
      "metadata": {
        "id": "eIbu3zg4A5jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "77TS4y7vLLD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coll = range(15)\n",
        "dl = DataLoader(coll, batch_size =5, shuffle = True)"
      ],
      "metadata": {
        "id": "KxJerD_-0uZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-a8HR6LDGUgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = list(dl)"
      ],
      "metadata": {
        "id": "hC0b3nq9GXOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_wp_uMyGt3p",
        "outputId": "96b4e04a-5004-4a05-852c-0bf62d1f1195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 3,  2, 10,  9, 13]),\n",
              " tensor([14,  6,  8,  0,  1]),\n",
              " tensor([ 7,  4,  5, 12, 11])]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc(list)"
      ],
      "metadata": {
        "id": "Rvbto0nOGu-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "30a61fbd-a3de-419b-a607-18b361f38ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h2 id=\"list\" class=\"doc_header\"><code>class</code> <code>list</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2><blockquote><p><code>list</code>(<strong><code>iterable</code></strong>=<em><code>()</code></em>)</p>\n",
              "</blockquote>\n",
              "<p>Built-in mutable sequence.</p>\n",
              "<p>If no argument is given, the constructor creates a new empty list.\n",
              "The argument must be an iterable if specified.</p>\n",
              "<style>\n",
              "    table { border-collapse: collapse; border:thin solid #dddddd; margin: 25px 0px; ; }\n",
              "    table tr:first-child { background-color: #FFF}\n",
              "    table thead th { background-color: #eee; color: #000; text-align: center;}\n",
              "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
              "    padding: 5px; }\n",
              "    tr:nth-child(even) {background: #eee;}</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The independent variables are the inputs while the dependent variables are the targets.\n",
        "\n",
        "In pytorch a dataset is a collection that contains independent and dependent variables. (x,y) x is the training inputs y is the labeled data."
      ],
      "metadata": {
        "id": "zzxvfiK6G-QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = L(enumerate(string.ascii_lowercase))"
      ],
      "metadata": {
        "id": "XKzubyttG0Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELm9hdzbIfMe",
        "outputId": "15590172-ef03-4014-a608-c4f7f26c9353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size=5, shuffle = True)"
      ],
      "metadata": {
        "id": "JTcKhNRWIf-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WclvoFt7JJW-",
        "outputId": "ab0a4187-cf53-42db-9637-dabf00c52e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.data.load.DataLoader at 0x7f543818ab50>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ676VkkJKSa",
        "outputId": "8a59472b-1f52-4155-9eb0-0c426fcdaec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 3, 16, 17,  8,  7]), ('d', 'q', 'r', 'i', 'h')),\n",
              " (tensor([ 2, 10, 22,  4, 14]), ('c', 'k', 'w', 'e', 'o')),\n",
              " (tensor([25, 15,  1, 12, 19]), ('z', 'p', 'b', 'm', 't')),\n",
              " (tensor([ 5,  9, 11,  0, 23]), ('f', 'j', 'l', 'a', 'x')),\n",
              " (tensor([21, 13, 18, 20,  6]), ('v', 'n', 's', 'u', 'g')),\n",
              " (tensor([24]), ('y',))]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_list  = list(dl)"
      ],
      "metadata": {
        "id": "sANJhjc3JOLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NvuRa7gJRYP",
        "outputId": "77e67f36-1998-4ff0-b896-3e3c89fbc9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 7,  6, 17, 12,  5]), ('h', 'g', 'r', 'm', 'f')),\n",
              " (tensor([22, 23, 10, 18, 13]), ('w', 'x', 'k', 's', 'n')),\n",
              " (tensor([11, 24,  2, 15, 14]), ('l', 'y', 'c', 'p', 'o')),\n",
              " (tensor([25, 19,  4,  3,  9]), ('z', 't', 'e', 'd', 'j')),\n",
              " (tensor([ 8, 16, 21,  0, 20]), ('i', 'q', 'v', 'a', 'u')),\n",
              " (tensor([1]), ('b',))]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dl:\n",
        "  pred = model(x) #We pass in our input data into the models \n",
        "  loss = loss_fn(pred,y) #We calculate the loss based on the predictions and the target variables loss = (y - ^Y )2 pred = ^y, y target variable\n",
        "  loss.backward() #We do backpropagation after calculating the loss\n",
        "  parameters -= parameters.grad * lr #We update the parameters by taking the difference of the stepsize( i.e learning rate * the gradient descent) a\n",
        "  \n"
      ],
      "metadata": {
        "id": "pp2L-UEJJTj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually we start by initializing the parameters to random values to allow gradient descent to take place effectively. We do random initialization because if we don't our layers will give constant/same outputs and hence hindering gradient descent from taking place effectively."
      ],
      "metadata": {
        "id": "cHsvAAZJPNyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = init_params((28 * 28 , 1))#We initialise the weights randomly through the init_params method"
      ],
      "metadata": {
        "id": "z98nOyaWK9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(dset, batch_size=256) #We load the dataset to a batch size of 256"
      ],
      "metadata": {
        "id": "8AxRfqbmP74Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb ,yb = first(dl) #We then split the dataset into training and labeled data"
      ],
      "metadata": {
        "id": "h87i8EcDQkVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_BP0sKZRj7D",
        "outputId": "12910fc5-cfaf-4806-bddf-2ecb93136e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization is changing and updating the weights based on the gradient. To take an optimization step, we need to calculate the loss of the whole dataset or single data item.Calculating for the whole dataset will take a much longer time and calculating for a single data item means changing and updating the weights of a single item which will result in imprecise calculations which will lead to unstable gradients. The ideal way to go about this is to calculate the average loss of a few data items at time this is called mini-batch."
      ],
      "metadata": {
        "id": "2lrFAvfY_-VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = L(enumerate(string.ascii_lowercase))"
      ],
      "metadata": {
        "id": "nbrLLVs7RoEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEiKWpfeDxc8",
        "outputId": "5f37928a-6697-4028-9c3b-b1a6432caca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds,batch_size=5,shuffle = True)"
      ],
      "metadata": {
        "id": "o6OoDFP7Dy3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwjai73OEEEs",
        "outputId": "e4d1545a-c6bb-4e2f-fdd6-ffc4df323350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 6, 14, 12, 15, 24]), ('g', 'o', 'm', 'p', 'y')),\n",
              " (tensor([11,  0, 16,  2, 18]), ('l', 'a', 'q', 'c', 's')),\n",
              " (tensor([25, 21,  8,  7, 19]), ('z', 'v', 'i', 'h', 't')),\n",
              " (tensor([23,  1,  9,  4, 13]), ('x', 'b', 'j', 'e', 'n')),\n",
              " (tensor([10,  5,  3, 17, 22]), ('k', 'f', 'd', 'r', 'w')),\n",
              " (tensor([20]), ('u',))]"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a dataset \n",
        "ds  = L(enumerate(string.ascii_lowercase)) "
      ],
      "metadata": {
        "id": "Mk05bkjREKLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We pass the dataset into a list \n",
        "list(ds)"
      ],
      "metadata": {
        "id": "afqebDo3E2r6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0e95bb-be4a-4dec-924f-e773da9be355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'a'),\n",
              " (1, 'b'),\n",
              " (2, 'c'),\n",
              " (3, 'd'),\n",
              " (4, 'e'),\n",
              " (5, 'f'),\n",
              " (6, 'g'),\n",
              " (7, 'h'),\n",
              " (8, 'i'),\n",
              " (9, 'j'),\n",
              " (10, 'k'),\n",
              " (11, 'l'),\n",
              " (12, 'm'),\n",
              " (13, 'n'),\n",
              " (14, 'o'),\n",
              " (15, 'p'),\n",
              " (16, 'q'),\n",
              " (17, 'r'),\n",
              " (18, 's'),\n",
              " (19, 't'),\n",
              " (20, 'u'),\n",
              " (21, 'v'),\n",
              " (22, 'w'),\n",
              " (23, 'x'),\n",
              " (24, 'y'),\n",
              " (25, 'z')]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We the create a dataloader\n",
        "dl = DataLoader(ds, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "V6_2JdInE8Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xcwO2GAFMkX",
        "outputId": "84fa19d6-03e8-452a-87bf-ae2cd8bcfd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([20, 18, 21,  5,  6]), ('u', 's', 'v', 'f', 'g')),\n",
              " (tensor([ 9, 13, 19, 12, 16]), ('j', 'n', 't', 'm', 'q')),\n",
              " (tensor([25,  3, 15,  1,  0]), ('z', 'd', 'p', 'b', 'a')),\n",
              " (tensor([24, 10, 23, 11, 22]), ('y', 'k', 'x', 'l', 'w')),\n",
              " (tensor([ 2,  4, 14, 17,  7]), ('c', 'e', 'o', 'r', 'h')),\n",
              " (tensor([8]), ('i',))]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dl:\n",
        "  pred = model(x) #We get the predictions from our model \n",
        "  loss = loss_fn(pred, y) #We caluculate the loss using the loss function loss_fn which takes in the predictions and the target labels\n",
        "  loss.backward() #We do a backpropagation of the loss using the backward method from pytorch \n",
        "  parameters -= parameters.grad * lr #We apply gradient descent i.e changing the parameters which is updating the weights and bias based on the loss\n",
        "  "
      ],
      "metadata": {
        "id": "vVMznB8oHPTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start training by initializing random weights\n",
        "weights = init_params((28*28,1))"
      ],
      "metadata": {
        "id": "5-AvU1a6G65u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "7QLrAfq0FShj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We create a dataLoader from the dataset\n",
        "dl = DataLoader(dset, batch_size=256)"
      ],
      "metadata": {
        "id": "bcw8yFqiEwqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = first(dl)"
      ],
      "metadata": {
        "id": "s0zZcbNxJhRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMSIT-H7JkEo",
        "outputId": "1ddcbfb8-0a22-43b9-e529-3676c7567721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(predictions, targets):\n",
        "  sm_acts = torch.softmax(predictions, dim = 1)\n",
        "  idx = len(predictions)\n"
      ],
      "metadata": {
        "id": "KAkxLROVV59A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QJVa31CFWYVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_grad(xb,yb, model):\n",
        "  pred = model(xb)\n",
        "  loss = cross_entropy_loss(preds,yb)\n",
        "  loss.backward()"
      ],
      "metadata": {
        "id": "eClajRXxRlhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc(calc_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5O-qO4bTnsJ",
        "outputId": "f42f3635-461c-4b42-947f-c45a2261292a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calc_grad(xb, yb, model)\n",
            "None\n",
            "\n",
            "To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbdev"
      ],
      "metadata": {
        "id": "2Jy8zjEMTrbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ce507a-9a88-48e6-b21f-0fd0c23f4bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbdev in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nbdev) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from nbdev) (3.13)\n",
            "Requirement already satisfied: ghapi in /usr/local/lib/python3.7/dist-packages (from nbdev) (0.1.19)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev) (5.1.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.7/dist-packages (from nbdev) (7.1.2)\n",
            "Requirement already satisfied: nbconvert>=6.1 in /usr/local/lib/python3.7/dist-packages (from nbdev) (6.4.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from nbdev) (21.1.3)\n",
            "Requirement already satisfied: fastrelease in /usr/local/lib/python3.7/dist-packages (from nbdev) (0.1.12)\n",
            "Requirement already satisfied: fastcore>=1.3.29 in /usr/local/lib/python3.7/dist-packages (from nbdev) (1.3.29)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (5.1.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (4.9.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (5.1.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (1.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8->nbdev) (22.3.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (2.11.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (1.5.0)\n",
            "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (0.5.11)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (4.1.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (0.1.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (0.8.4)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (2.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.1->nbdev) (0.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert>=6.1->nbdev) (2.0.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev) (0.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (4.11.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (3.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client<8->nbdev) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.1->nbdev) (0.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->nbdev) (0.2.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (7.6.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev) (3.5.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev) (1.8.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nbdev) (0.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nbdev) (3.0.7)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights.grad"
      ],
      "metadata": {
        "id": "IgLXpJ7eT763"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dl:\n",
        "  pred = model(x)\n",
        "  loss = loss_fn(pred,y)\n",
        "  loss.backward()\n",
        "  parameters -= parameter.grad * lr  "
      ],
      "metadata": {
        "id": "DvSfyoYXSJ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u32Z8FOLV2K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = (xb,yb)\n",
        "\n",
        "calc_grad(xb,yb[:4], linear1)\n"
      ],
      "metadata": {
        "id": "C4Y1RLI4Jlzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = L(enumerate(string.ascii_lowercase))"
      ],
      "metadata": {
        "id": "SCSJICKIVqwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds , batch_size=5, shuffle = True)"
      ],
      "metadata": {
        "id": "wED0Jz4w78Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6z8O4SD8UvC",
        "outputId": "c8a3b3e4-f47b-4c0a-b243-805b0bff68cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([ 1,  4, 21,  5, 17]), ('b', 'e', 'v', 'f', 'r')),\n",
              " (tensor([24, 23,  9, 22, 13]), ('y', 'x', 'j', 'w', 'n')),\n",
              " (tensor([ 2,  6, 16, 12, 14]), ('c', 'g', 'q', 'm', 'o')),\n",
              " (tensor([ 7, 20, 15,  8, 18]), ('h', 'u', 'p', 'i', 's')),\n",
              " (tensor([ 3,  0, 25, 19, 11]), ('d', 'a', 'z', 't', 'l')),\n",
              " (tensor([10]), ('k',))]"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dl:\n",
        "  pred = model(x)\n",
        "  loss = loss_fn(pred, y)\n",
        "  loss.backward()\n",
        "  parameters -= parameters * lr"
      ],
      "metadata": {
        "id": "rKsQE_2a8XTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reinitialise the parameters\n",
        "weights = init_params((28 * 28, 1))"
      ],
      "metadata": {
        "id": "cO12yWLb82cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "XesEnjD09Bsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We then create a dataloader from the dataset \n",
        "dl = DataLoader(dset, batch_size= 256)"
      ],
      "metadata": {
        "id": "E9rYqWY59DL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNwfbRUm9RHt",
        "outputId": "493546a5-bc40-490e-8c0f-1a6447775b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.data.load.DataLoader at 0x7f543818a150>"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_grad(batch, train_y[:4], linear1)\n",
        "weights.grad.mean(), bias.grad"
      ],
      "metadata": {
        "id": "CtwjqmA7JHy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.grad.zero_()"
      ],
      "metadata": {
        "id": "vgsO4e37KsH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias.grad.zero_()"
      ],
      "metadata": {
        "id": "KEY4iuVCL98M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch( model , lr, params):\n",
        "  for xb , yb in dl:\n",
        "    calc_grad(xb, yb, model)\n",
        "  for p in params:\n",
        "    p.data -= p.grad.zero * lr\n",
        "    p.grad.zero_()"
      ],
      "metadata": {
        "id": "Nz4W3XMHL7PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(preds>0.0).float() == train_y[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "GVqdGgxePdGv",
        "outputId": "ed7c6c93-1f37-4469-fd95-e7d42acd4dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-211-b2d29767b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(xb,yb):\n",
        "  preds = xb.sigmoid()\n",
        "  correct = (preds>0.5) == yb\n",
        "  return correct.float.mean()\n"
      ],
      "metadata": {
        "id": "FrDKMG5s8AjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_accuracy(linear1(batch), train_y[:4])"
      ],
      "metadata": {
        "id": "7gHYZkyTRqem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model):\n",
        "  accs = [batch_accuracy(model(xb), yb) for xb , yb in valid_dl]\n",
        "  return round(torch.stack(accs).mean().item(), 4)"
      ],
      "metadata": {
        "id": "SYWFztpXSX8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_epoch(linear1)"
      ],
      "metadata": {
        "id": "Nz7G1ejTT1XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1 \n",
        "params = weights,bias\n",
        "train_epoch(linear1, lr, params)\n",
        "validate_epoch(linear1)"
      ],
      "metadata": {
        "id": "UkT8B7V-T5SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  train_epoch(linear1, lr , params)\n",
        "  print(validate_epoch(linear1), end='')"
      ],
      "metadata": {
        "id": "oOHTFEXtVSCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient descent which is an automated learning technique that involves changing the weights and the biases based on the loss functions\n",
        "import  torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "linear_model = nn.Linear(28 * 28 ,1)"
      ],
      "metadata": {
        "id": "Z_nqWPaAWiHY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w,b = linear_model.parameters()"
      ],
      "metadata": {
        "id": "ji2lANnpCagZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yhNTWzeCptf",
        "outputId": "5f1b1e3b-851b-4343-9ec5-017e0aa83b02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xkoX4opCrBe",
        "outputId": "6436fc02-3d8f-48b3-daa5-dbebe3f7e957"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We create an optimizer class\n",
        "class BasicOptim:\n",
        "  def __init__(self, params, lr):\n",
        "    self.params,\n",
        "    self.lr = list(params), \n",
        "    lr\n",
        "  def step(self, *args, **kwargs):\n",
        "    for p in params:p.data -= p.data.grad * self.lr"
      ],
      "metadata": {
        "id": "x0wOgnDoCsPQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VbUGEJK0HT0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sUqi72V_G7Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nVk232N4Gu6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MDF92WczGpg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jw4uHk9mGl5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "__zzwmCGFEKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-UiRkJ6bD7Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NCZf3b39D5PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DCkWXT6nDlE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WcVAXe1mDgzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U-EVhbLvDVgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2axzcOygCXNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HnJB5r_eCRgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gNIJVWOaCPNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8bvLg47uCAux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LrHNHStFB7e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DMdcqPE3B2i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LmSEX2AfB0mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j7T3bSRYWaop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pwb-5-NoTjwr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNISTLOSS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFgBfKMhVz3OTYpLh2550q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}