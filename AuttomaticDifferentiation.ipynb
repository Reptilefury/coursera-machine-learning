{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reptilefury/coursera-machine-learning/blob/main/AuttomaticDifferentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5phvWV2Ld8Xv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import  DataLoader\n",
        "from torchvision import  datasets, transforms\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ghv_okXekfH"
      },
      "outputs": [],
      "source": [
        "#We check for GPU availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRWwjVyke2iK"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.FashionMNIST( \n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform= ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0 , torch.tensor(y), value=1))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de3CZF4WfeJu"
      },
      "outputs": [],
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform =ToTensor(),\n",
        "    target_transform = Lambda(lambda y: torch.zero(0,dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnFFoOhVf9K5"
      },
      "outputs": [],
      "source": [
        "#We define our neural network through subclassing the nn.Module class\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "    self.layer_relu_stack = torch.nn.Sequential(\n",
        "        #torch.nn.Linear(28 * 28,512),\n",
        "        torch.nn.Linear(28 * 28 , 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,10),\n",
        "        torch.nn.ReLU()\n",
        "        )\n",
        "  def forward(self,x):\n",
        "      x = self.flatten(x),\n",
        "      logits = self.layer_relu_stack(x)\n",
        "      return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJjAYkMlpY9G"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US0c765dqC2U"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork5(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork5,self).__init__()\n",
        "    self.flatten = torch.nn.Flatten(),\n",
        "    self.seq = torch.nn.Sequential(\n",
        "        torch.nn.Linear(28 * 28 , 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,10),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      logits  = self.seq(x)\n",
        "      return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBolZ_15zDRe"
      },
      "outputs": [],
      "source": [
        "#We create an instance of the model we pass it to the GPU\n",
        "model = NeuralNetwork5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGYVRRR50BOt"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(1, 28  * 28 ,device=device)\n",
        "logits = model(x)\n",
        "pred_prob = torch.softmax(dim=1)(logits)\n",
        "#y_pred = pred_prob.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tU5GSyNtyt1"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(5)\n",
        "y = torch.zeros(3)\n",
        "w = torch.randn(5,3 , requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x,w) + b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkVOTELxIzbG"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(5)\n",
        "y = torch.zeros(3)\n",
        "w = torch.randn(5,3, requires_grad=True)\n",
        "b = torch.randn(3,requires_grad=True)\n",
        "z = torch.matmul(x,w) + b \n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v733vkOtT4SD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSg0yNXNbxjO"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmAWHfPOb4Rl"
      },
      "outputs": [],
      "source": [
        "#load the dataset \n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    download = True, \n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = Lambda(lambda y:torch.zeros(10,dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IZASbxid4sh"
      },
      "outputs": [],
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\", \n",
        "    download = True, \n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = Lambda(lambda y:torch.zeros(0, dtype= torch.float).scatter_(0, torch.tensor(y), value =1))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxAI07zRepP4"
      },
      "outputs": [],
      "source": [
        "#We now build the neural network\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "    self.linear_relu_stack = torch.nn.Sequential(\n",
        "        torch.nn.Linear(28 * 28, 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512,10),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x),\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTATNbRhepFy"
      },
      "outputs": [],
      "source": [
        "#We create an instance of the neural network and pass it to the GPU \n",
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87lo1mZOgLFq"
      },
      "outputs": [],
      "source": [
        "X = torch.rand(1, 28 * 28,device = device)\n",
        "logits = model(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC04E_l_h3cz"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZp4LGJTiQWW"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOJ4YLkQiWxl"
      },
      "outputs": [],
      "source": [
        "X= torch.rand(1,28 * 28 , device=device)\n",
        "logits = model(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oWlRf-sijr5"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork2, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.seq = nn.Sequential(\n",
        "        nn.Linear(28 * 28 , 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),)\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.seq(x)\n",
        "    return logits\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uhDIBjXgLC1"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork2().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED_JhKWqjmd9"
      },
      "outputs": [],
      "source": [
        "X = torch.rand(1,28 * 28 , device=device )\n",
        "logits = model(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_DoEq9XwkUxG"
      },
      "outputs": [],
      "source": [
        "#Automatic differentiation with Pytorch \n",
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVjax77DjXXy"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"Data\",\n",
        "    download = True,\n",
        "    train = True, \n",
        "    transform = ToTensor(),\n",
        "    target_transform = Lambda( lambda y:torch.zeros(10,dtype=torch.float).scatter_(0,torch.tensor(y), value=1))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data =  datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = Lambda(lambda y:torch.zeros(10,dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        "    )"
      ],
      "metadata": {
        "id": "-b-iNkK5i-qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the data to check whether the data is correctly labeled \n",
        "figure = plt.figure(figsize = (10,10))\n",
        "cols,rows = 3,3\n",
        "for i in range(1,cols * rows + 1):\n",
        "  simple_idx = torch.randint(len(training_data), size=(1,)).item()  \n",
        "  image, labels = training_data[simple_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.imshow(image.squeeze(), cmap='gray')\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "Vv6O7JCNjiV7",
        "outputId": "459ba710-1f47-445a-d4ae-5be63c52bab0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the computational graph \n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.layers_relu_stack = nn.Sequential(\n",
        "      nn.Linear(28 * 28,512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,10)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.layers_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "-h8eUbgikWYU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#Create an instance of the model\n",
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "tdVQnnh9lfKz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs\n",
        "x = torch.randn(1,28,28, device = device)\n",
        "logits = model(x)\n",
        "pred_probab = torch.nn.Softmax(dim=1)(logits)\n",
        "y_pred = torch.argmax(pred_probab)\n",
        "y_pred2 = pred_probab.argmax(1)"
      ],
      "metadata": {
        "id": "fSzf47cIl4BI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Automatic differentiation with Pytorch \n",
        "#Lets build a single layer neural network\n",
        "x = torch.zeros(5) #These are the inputs \n",
        "y = torch.ones(3) #Targets/Ground truth/labels\n",
        "w = torch.randn(5,3, requires_grad=True) #These are the weights of our model we allow automatic differentiation to be applied to them\n",
        "b = torch.randn(3, requires_grad=True) #This is the bias term we allow automatic differentiation/ Backpropagation of affect them\n",
        "z = torch.matmul(x,w) #Dot product of the weights  transpose of the inputs x\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)#Calculate the loss which is the distance between the predicted value and the desired value\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XnXUj44mlkK",
        "outputId": "fb8929c5-83ae-45ac-8dd0-bad87a3a4383"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNGQQ1BlxTQn",
        "outputId": "e2857a6c-2c9a-4922-bfa9-91a2006fedfe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n1vVcMzvxVBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We calculate the gradient of the loss fuction and use that gradient to update the values w and b: parameters weights and bias\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "XlMDVmajmDZQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_grad = print(w.grad) #gradient of the weights "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxnebutAslwu",
        "outputId": "57761984-58b4-4438-b254-9debccc35f3c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TIqFaNGt_xL",
        "outputId": "89481b90-6220-4f47-8079-866efe8a8541"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(z.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lhIZSs_uDXz",
        "outputId": "488e625a-51d9-4dde-d341-97a483162f72"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SqueezeBackward3 object at 0x7f3525ebef90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1R8jmY6uMtE",
        "outputId": "9635bbe3-ed3e-4088-c760-0771a5cf079b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BinaryCrossEntropyWithLogitsBackward0 object at 0x7f3525fc7310>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to optmize the values of w and b (parameters). We need to calculate the derivative of the loss function with respect to the specific parameters w and b under a some fixed value of x and y. In order to do that we use the loss.backward method and get the gradient values of w and b"
      ],
      "metadata": {
        "id": "6xq7hkyoujvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward() #Calculate the derivative "
      ],
      "metadata": {
        "id": "KhdmgGbNjHMw"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the gradient values of w \n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QcrgXi1vmXG",
        "outputId": "c45eb7d9-7c33-4bd4-b412-5a324be05010"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.],\n",
            "        [-0., -0., -0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.grad)\n",
        "print(b.requires_grad) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu58MaGyvzbN",
        "outputId": "47873f1d-1a81-4938-d769-ec02de643d31"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can disable gradient tracking for several reason such as:\n",
        "When we only want to do forward computations through our network by applying our model to some input we can disable gradient tracking."
      ],
      "metadata": {
        "id": "g9F0wgTWwO3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#A good example of diabling gradient tracking would be to surround the code with torch.no_grad\n",
        "z = torch.matmul(x,w) + b\n",
        "print(z.requires_grad) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWNHvcVpv1gJ",
        "outputId": "265cf140-0a75-4ed7-9840-33416b548916"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Disable gradient tracking\n",
        "with torch.no_grad():\n",
        "  z = torch.matmul(x,w)"
      ],
      "metadata": {
        "id": "OCrnApasxNIR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(z.requires_grad) #Here we have disabled gradient tracking and we could do this in situations where we want to only do forward computations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v83bO2kLx2gi",
        "outputId": "e642e227-772b-4584-c362-6691f415cb76"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Another quick way to disable gradient tracking is to use the detach method \n",
        "z = torch.matmul(x,w) + b\n",
        "z_detach = z.detach()\n",
        "print(z_detach.requires_grad) #Here we have disabled gradient tracking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytD-1PLuyFky",
        "outputId": "cf6c5226-9653-4d8e-efdf-cb699f34172c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More on Computation Graphs"
      ],
      "metadata": {
        "id": "Eo0mFGkjzWJn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AuttomaticDifferentiation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqBiqsQ1K0L95lX9GaGYPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}